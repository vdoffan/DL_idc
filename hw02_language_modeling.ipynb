{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "Ваша основная задача: научиться генерироват стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu device is available\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = torch.device('cpu')\n",
    "print('{} device is available'.format(device))\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "# !wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r', encoding='utf-8') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text])\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + ['<sos>']\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)}\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятие №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "batch_size = 256\n",
    "seq_length = 100\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>']\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1)\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "# __________end of block__________    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 70, 50, ..., 55, 64, 68],\n",
       "       [83, 53, 56, ..., 49, 61, 64],\n",
       "       [83, 51, 46, ..., 63, 72, 56],\n",
       "       ...,\n",
       "       [83, 55, 53, ..., 53,  1, 56],\n",
       "       [83, 45, 62, ...,  1, 53, 66],\n",
       "       [83,  1, 49, ..., 45, 50, 63]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generate_chunk())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели Vanilla RNN\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, output_size, num_layers=1):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Встраивание символов\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        \n",
    "        # Рекуррентный слой\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, nonlinearity='tanh', batch_first=True)\n",
    "        \n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embed_size)\n",
    "        out, hidden = self.rnn(embedded, hidden)  # out: (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.size(0)*out.size(1), self.hidden_size)  # (batch_size*seq_length, hidden_size)\n",
    "        out = self.fc(out)  # (batch_size*seq_length, output_size)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Инициализация скрытого состояния\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.003\n",
    "\n",
    "# Инициализация модели\n",
    "model = VanillaRNN(input_size=num_tokens, \n",
    "                   embed_size=embed_size, \n",
    "                   hidden_size=hidden_size, \n",
    "                   output_size=num_tokens, \n",
    "                   num_layers=num_layers).to(device)\n",
    "\n",
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 завершена --- tensor(4.4388, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 2 завершена --- tensor(3.9918, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 3 завершена --- tensor(3.4054, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 4 завершена --- tensor(3.2558, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 5 завершена --- tensor(3.1763, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 6 завершена --- tensor(3.1214, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 7 завершена --- tensor(3.0181, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 8 завершена --- tensor(2.9383, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 9 завершена --- tensor(2.8963, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 10 завершена --- tensor(2.8723, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 11 завершена --- tensor(2.8543, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 12 завершена --- tensor(2.8180, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 13 завершена --- tensor(2.7783, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 14 завершена --- tensor(2.7744, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 15 завершена --- tensor(2.7363, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 16 завершена --- tensor(2.7027, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 17 завершена --- tensor(2.6652, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 18 завершена --- tensor(2.6589, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 19 завершена --- tensor(2.6354, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 20 завершена --- tensor(2.6017, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 21 завершена --- tensor(2.5855, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 22 завершена --- tensor(2.5734, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 23 завершена --- tensor(2.5545, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 24 завершена --- tensor(2.5612, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 25 завершена --- tensor(2.5230, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 26 завершена --- tensor(2.5242, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 27 завершена --- tensor(2.5052, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 28 завершена --- tensor(2.5133, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 29 завершена --- tensor(2.5027, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 30 завершена --- tensor(2.4689, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 31 завершена --- tensor(2.4712, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 32 завершена --- tensor(2.4641, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 33 завершена --- tensor(2.4598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 34 завершена --- tensor(2.4424, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 35 завершена --- tensor(2.4254, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 36 завершена --- tensor(2.4194, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 37 завершена --- tensor(2.4079, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 38 завершена --- tensor(2.4160, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 39 завершена --- tensor(2.3993, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 40 завершена --- tensor(2.3858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 41 завершена --- tensor(2.3719, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 42 завершена --- tensor(2.3962, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 43 завершена --- tensor(2.3487, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 44 завершена --- tensor(2.3558, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 45 завершена --- tensor(2.3404, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 46 завершена --- tensor(2.3232, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 47 завершена --- tensor(2.3137, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 48 завершена --- tensor(2.3000, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 49 завершена --- tensor(2.3201, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 50 завершена --- tensor(2.2829, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 51 завершена --- tensor(2.2663, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 52 завершена --- tensor(2.3222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 53 завершена --- tensor(2.3071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 54 завершена --- tensor(2.2956, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 55 завершена --- tensor(2.2520, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 56 завершена --- tensor(2.2333, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 57 завершена --- tensor(2.2781, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 58 завершена --- tensor(2.2747, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 59 завершена --- tensor(2.2669, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 60 завершена --- tensor(2.2495, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 61 завершена --- tensor(2.2109, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 62 завершена --- tensor(2.2173, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 63 завершена --- tensor(2.1871, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 64 завершена --- tensor(2.2273, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 65 завершена --- tensor(2.1873, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 66 завершена --- tensor(2.1886, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 67 завершена --- tensor(2.2121, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 68 завершена --- tensor(2.2029, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 69 завершена --- tensor(2.1967, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 70 завершена --- tensor(2.2274, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 71 завершена --- tensor(2.1732, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 72 завершена --- tensor(2.1872, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 73 завершена --- tensor(2.1751, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 74 завершена --- tensor(2.1622, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 75 завершена --- tensor(2.1843, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 76 завершена --- tensor(2.1466, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 77 завершена --- tensor(2.1378, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 78 завершена --- tensor(2.1497, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 79 завершена --- tensor(2.1290, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 80 завершена --- tensor(2.1138, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 81 завершена --- tensor(2.1574, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 82 завершена --- tensor(2.1563, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 83 завершена --- tensor(2.1223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 84 завершена --- tensor(2.1570, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 85 завершена --- tensor(2.0921, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 86 завершена --- tensor(2.0923, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 87 завершена --- tensor(2.0818, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 88 завершена --- tensor(2.0822, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 89 завершена --- tensor(2.0962, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 90 завершена --- tensor(2.0540, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 91 завершена --- tensor(2.0341, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 92 завершена --- tensor(2.0952, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 93 завершена --- tensor(2.1112, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 94 завершена --- tensor(2.1039, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 95 завершена --- tensor(2.1011, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 96 завершена --- tensor(2.0833, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 97 завершена --- tensor(2.1070, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 98 завершена --- tensor(2.0192, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 99 завершена --- tensor(2.0330, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 100 завершена --- tensor(2.0093, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 101 завершена --- tensor(1.9937, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 102 завершена --- tensor(2.0762, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 103 завершена --- tensor(1.9837, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 104 завершена --- tensor(2.0386, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 105 завершена --- tensor(1.9613, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 106 завершена --- tensor(2.0634, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 107 завершена --- tensor(2.0474, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 108 завершена --- tensor(2.0141, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 109 завершена --- tensor(2.0209, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 110 завершена --- tensor(1.9946, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 111 завершена --- tensor(2.0419, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 112 завершена --- tensor(1.9479, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 113 завершена --- tensor(2.0264, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 114 завершена --- tensor(1.9387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 115 завершена --- tensor(2.0375, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 116 завершена --- tensor(1.9464, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 117 завершена --- tensor(1.9784, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 118 завершена --- tensor(1.9808, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 119 завершена --- tensor(1.9769, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 120 завершена --- tensor(1.9640, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 121 завершена --- tensor(1.9580, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 122 завершена --- tensor(2.0013, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 123 завершена --- tensor(2.0048, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 124 завершена --- tensor(1.9658, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 125 завершена --- tensor(1.9809, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 126 завершена --- tensor(1.9223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 127 завершена --- tensor(1.9309, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 128 завершена --- tensor(1.9511, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 129 завершена --- tensor(1.9984, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 130 завершена --- tensor(1.9195, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 131 завершена --- tensor(1.9893, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 132 завершена --- tensor(1.8758, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 133 завершена --- tensor(1.9534, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 134 завершена --- tensor(1.9033, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 135 завершена --- tensor(1.9110, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 136 завершена --- tensor(1.9336, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 137 завершена --- tensor(1.8779, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 138 завершена --- tensor(1.8986, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 139 завершена --- tensor(1.8560, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 140 завершена --- tensor(1.8960, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 141 завершена --- tensor(1.9473, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 142 завершена --- tensor(1.8850, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 143 завершена --- tensor(1.8524, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 144 завершена --- tensor(1.8694, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 145 завершена --- tensor(1.9215, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 146 завершена --- tensor(1.8781, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 147 завершена --- tensor(1.9218, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 148 завершена --- tensor(1.8223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 149 завершена --- tensor(1.9162, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 150 завершена --- tensor(1.8031, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 151 завершена --- tensor(1.8805, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 152 завершена --- tensor(1.8575, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 153 завершена --- tensor(1.8840, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 154 завершена --- tensor(1.8068, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 155 завершена --- tensor(1.8492, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 156 завершена --- tensor(1.8702, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 157 завершена --- tensor(1.8344, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 158 завершена --- tensor(1.7752, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 159 завершена --- tensor(1.8094, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 160 завершена --- tensor(1.7663, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 161 завершена --- tensor(1.8266, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 162 завершена --- tensor(1.8141, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 163 завершена --- tensor(1.8977, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 164 завершена --- tensor(1.7757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 165 завершена --- tensor(1.7734, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 166 завершена --- tensor(1.8590, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 167 завершена --- tensor(1.7845, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 168 завершена --- tensor(1.7952, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 169 завершена --- tensor(1.7738, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 170 завершена --- tensor(1.7921, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 171 завершена --- tensor(1.8768, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 172 завершена --- tensor(1.7410, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 173 завершена --- tensor(1.8123, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 174 завершена --- tensor(1.8617, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 175 завершена --- tensor(1.8240, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 176 завершена --- tensor(1.7371, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 177 завершена --- tensor(1.8145, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 178 завершена --- tensor(1.7405, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 179 завершена --- tensor(1.7554, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 180 завершена --- tensor(1.7345, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 181 завершена --- tensor(1.7981, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 182 завершена --- tensor(1.6856, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 183 завершена --- tensor(1.7829, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 184 завершена --- tensor(1.8377, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 185 завершена --- tensor(1.7698, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 186 завершена --- tensor(1.7093, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 187 завершена --- tensor(1.8767, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 188 завершена --- tensor(1.8514, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 189 завершена --- tensor(1.8275, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 190 завершена --- tensor(1.8181, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 191 завершена --- tensor(1.7459, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 192 завершена --- tensor(1.6893, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 193 завершена --- tensor(1.7074, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 194 завершена --- tensor(1.7403, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 195 завершена --- tensor(1.7312, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 196 завершена --- tensor(1.7718, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 197 завершена --- tensor(1.7329, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 198 завершена --- tensor(1.7350, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 199 завершена --- tensor(1.8311, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 200 завершена --- tensor(1.6639, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 201 завершена --- tensor(1.7347, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 202 завершена --- tensor(1.6759, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 203 завершена --- tensor(1.7158, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 204 завершена --- tensor(1.7396, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 205 завершена --- tensor(1.7991, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 206 завершена --- tensor(1.7239, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 207 завершена --- tensor(1.8087, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 208 завершена --- tensor(1.8289, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 209 завершена --- tensor(1.7395, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 210 завершена --- tensor(1.7113, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 211 завершена --- tensor(1.6842, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 212 завершена --- tensor(1.7892, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 213 завершена --- tensor(1.6452, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 214 завершена --- tensor(1.8008, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 215 завершена --- tensor(1.6817, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 216 завершена --- tensor(1.7508, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 217 завершена --- tensor(1.6327, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 218 завершена --- tensor(1.7739, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 219 завершена --- tensor(1.6747, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 220 завершена --- tensor(1.7210, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 221 завершена --- tensor(1.7389, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 222 завершена --- tensor(1.7051, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 223 завершена --- tensor(1.6209, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 224 завершена --- tensor(1.5917, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 225 завершена --- tensor(1.7227, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 226 завершена --- tensor(1.7344, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 227 завершена --- tensor(1.6858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 228 завершена --- tensor(1.6958, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 229 завершена --- tensor(1.6657, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 230 завершена --- tensor(1.6989, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 231 завершена --- tensor(1.6661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 232 завершена --- tensor(1.6365, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 233 завершена --- tensor(1.6420, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 234 завершена --- tensor(1.6075, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 235 завершена --- tensor(1.7801, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 236 завершена --- tensor(1.6348, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 237 завершена --- tensor(1.6570, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 238 завершена --- tensor(1.5929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 239 завершена --- tensor(1.7303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 240 завершена --- tensor(1.6125, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 241 завершена --- tensor(1.6554, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 242 завершена --- tensor(1.5387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 243 завершена --- tensor(1.6489, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 244 завершена --- tensor(1.6017, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 245 завершена --- tensor(1.6469, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 246 завершена --- tensor(1.5122, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 247 завершена --- tensor(1.6406, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 248 завершена --- tensor(1.6091, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 249 завершена --- tensor(1.6257, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 250 завершена --- tensor(1.6218, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 251 завершена --- tensor(1.6190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 252 завершена --- tensor(1.5444, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 253 завершена --- tensor(1.6071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 254 завершена --- tensor(1.6467, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 255 завершена --- tensor(1.6021, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 256 завершена --- tensor(1.5698, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 257 завершена --- tensor(1.6216, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 258 завершена --- tensor(1.6135, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 259 завершена --- tensor(1.8070, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 260 завершена --- tensor(1.5017, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 261 завершена --- tensor(1.6537, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 262 завершена --- tensor(1.5775, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 263 завершена --- tensor(1.4916, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 264 завершена --- tensor(1.6102, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 265 завершена --- tensor(1.5191, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 266 завершена --- tensor(1.5935, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 267 завершена --- tensor(1.6080, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 268 завершена --- tensor(1.5661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 269 завершена --- tensor(1.5294, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 270 завершена --- tensor(1.5827, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 271 завершена --- tensor(1.5743, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 272 завершена --- tensor(1.5476, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 273 завершена --- tensor(1.4724, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 274 завершена --- tensor(1.5110, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 275 завершена --- tensor(1.5480, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 276 завершена --- tensor(1.5643, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 277 завершена --- tensor(1.4605, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 278 завершена --- tensor(1.6517, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 279 завершена --- tensor(1.5112, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 280 завершена --- tensor(1.5366, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 281 завершена --- tensor(1.4866, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 282 завершена --- tensor(1.5467, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 283 завершена --- tensor(1.6127, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 284 завершена --- tensor(1.4858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 285 завершена --- tensor(1.7168, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 286 завершена --- tensor(1.5316, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 287 завершена --- tensor(1.5285, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 288 завершена --- tensor(1.6311, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 289 завершена --- tensor(1.5253, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 290 завершена --- tensor(1.5071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 291 завершена --- tensor(1.4867, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 292 завершена --- tensor(1.4757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 293 завершена --- tensor(1.4949, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 294 завершена --- tensor(1.7933, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 295 завершена --- tensor(1.4905, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 296 завершена --- tensor(1.4624, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 297 завершена --- tensor(1.5924, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 298 завершена --- tensor(1.4729, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 299 завершена --- tensor(1.5929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 300 завершена --- tensor(1.4826, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 301 завершена --- tensor(1.4645, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 302 завершена --- tensor(1.4411, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 303 завершена --- tensor(1.4804, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 304 завершена --- tensor(1.4556, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 305 завершена --- tensor(1.4598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 306 завершена --- tensor(1.4291, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 307 завершена --- tensor(1.4443, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 308 завершена --- tensor(1.7845, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 309 завершена --- tensor(1.5152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 310 завершена --- tensor(1.5365, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 311 завершена --- tensor(1.5149, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 312 завершена --- tensor(1.4595, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 313 завершена --- tensor(1.4447, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 314 завершена --- tensor(1.4964, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 315 завершена --- tensor(1.4541, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 316 завершена --- tensor(1.4883, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 317 завершена --- tensor(1.4076, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 318 завершена --- tensor(1.4601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 319 завершена --- tensor(1.4207, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 320 завершена --- tensor(1.4548, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 321 завершена --- tensor(1.6602, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 322 завершена --- tensor(1.4173, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 323 завершена --- tensor(1.4706, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 324 завершена --- tensor(1.4504, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 325 завершена --- tensor(1.4664, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 326 завершена --- tensor(1.4140, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 327 завершена --- tensor(1.4152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 328 завершена --- tensor(1.4530, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 329 завершена --- tensor(1.4492, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 330 завершена --- tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 331 завершена --- tensor(1.4060, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 332 завершена --- tensor(1.4329, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 333 завершена --- tensor(1.4220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 334 завершена --- tensor(1.3546, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 335 завершена --- tensor(1.3798, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 336 завершена --- tensor(1.6349, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 337 завершена --- tensor(1.3282, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 338 завершена --- tensor(1.5082, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 339 завершена --- tensor(1.3932, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 340 завершена --- tensor(1.3140, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 341 завершена --- tensor(1.3810, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 342 завершена --- tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 343 завершена --- tensor(1.4340, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 344 завершена --- tensor(1.4298, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 345 завершена --- tensor(1.3662, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 346 завершена --- tensor(1.3301, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 347 завершена --- tensor(1.5102, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 348 завершена --- tensor(1.4211, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 349 завершена --- tensor(1.4519, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 350 завершена --- tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 351 завершена --- tensor(1.3047, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 352 завершена --- tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 353 завершена --- tensor(1.6654, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 354 завершена --- tensor(1.3606, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 355 завершена --- tensor(1.3596, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 356 завершена --- tensor(1.7728, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 357 завершена --- tensor(1.3844, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 358 завершена --- tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 359 завершена --- tensor(1.3723, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 360 завершена --- tensor(1.2968, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 361 завершена --- tensor(1.3601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 362 завершена --- tensor(1.4757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 363 завершена --- tensor(1.6898, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 364 завершена --- tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 365 завершена --- tensor(1.2964, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 366 завершена --- tensor(1.6250, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 367 завершена --- tensor(1.3585, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 368 завершена --- tensor(1.2794, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 369 завершена --- tensor(1.3765, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 370 завершена --- tensor(1.6035, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 371 завершена --- tensor(1.3655, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 372 завершена --- tensor(1.4142, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 373 завершена --- tensor(1.2667, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 374 завершена --- tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 375 завершена --- tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 376 завершена --- tensor(1.3121, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 377 завершена --- tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 378 завершена --- tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 379 завершена --- tensor(1.2367, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 380 завершена --- tensor(1.3523, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 381 завершена --- tensor(1.3615, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 382 завершена --- tensor(1.6084, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 383 завершена --- tensor(1.4336, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 384 завершена --- tensor(1.1996, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 385 завершена --- tensor(1.4094, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 386 завершена --- tensor(1.3461, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 387 завершена --- tensor(1.3134, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 388 завершена --- tensor(1.4196, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 389 завершена --- tensor(1.3507, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 390 завершена --- tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 391 завершена --- tensor(1.3533, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 392 завершена --- tensor(1.3585, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 393 завершена --- tensor(1.5180, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 394 завершена --- tensor(1.3621, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 395 завершена --- tensor(1.2692, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 396 завершена --- tensor(1.4195, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 397 завершена --- tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 398 завершена --- tensor(1.5590, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 399 завершена --- tensor(1.3190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 400 завершена --- tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 401 завершена --- tensor(1.3071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 402 завершена --- tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 403 завершена --- tensor(1.2387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 404 завершена --- tensor(1.2319, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 405 завершена --- tensor(1.5224, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 406 завершена --- tensor(1.2029, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 407 завершена --- tensor(1.3083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 408 завершена --- tensor(1.2655, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 409 завершена --- tensor(1.2852, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 410 завершена --- tensor(1.3442, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 411 завершена --- tensor(1.2306, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 412 завершена --- tensor(1.4997, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 413 завершена --- tensor(1.3594, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 414 завершена --- tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 415 завершена --- tensor(1.3576, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 416 завершена --- tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 417 завершена --- tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 418 завершена --- tensor(1.1686, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 419 завершена --- tensor(1.1767, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 420 завершена --- tensor(1.2484, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 421 завершена --- tensor(1.3036, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 422 завершена --- tensor(1.2726, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 423 завершена --- tensor(1.4296, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 424 завершена --- tensor(1.3969, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 425 завершена --- tensor(1.4816, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 426 завершена --- tensor(1.1681, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 427 завершена --- tensor(1.1283, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 428 завершена --- tensor(1.4089, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 429 завершена --- tensor(1.2629, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 430 завершена --- tensor(1.2844, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 431 завершена --- tensor(1.3170, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 432 завершена --- tensor(1.2885, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 433 завершена --- tensor(1.3079, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 434 завершена --- tensor(1.2815, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 435 завершена --- tensor(1.3162, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 436 завершена --- tensor(1.2157, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 437 завершена --- tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 438 завершена --- tensor(1.2811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 439 завершена --- tensor(1.3047, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 440 завершена --- tensor(1.1301, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 441 завершена --- tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 442 завершена --- tensor(1.3571, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 443 завершена --- tensor(1.2054, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 444 завершена --- tensor(1.2596, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 445 завершена --- tensor(1.0957, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 446 завершена --- tensor(1.0815, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 447 завершена --- tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 448 завершена --- tensor(1.2193, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 449 завершена --- tensor(1.2170, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 450 завершена --- tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 451 завершена --- tensor(1.2849, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 452 завершена --- tensor(1.1210, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 453 завершена --- tensor(1.1054, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 454 завершена --- tensor(1.0608, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 455 завершена --- tensor(1.1416, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 456 завершена --- tensor(1.1896, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 457 завершена --- tensor(1.1894, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 458 завершена --- tensor(1.0687, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 459 завершена --- tensor(1.1496, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 460 завершена --- tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 461 завершена --- tensor(1.2462, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 462 завершена --- tensor(1.1164, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 463 завершена --- tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 464 завершена --- tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 465 завершена --- tensor(1.2039, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 466 завершена --- tensor(1.0690, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 467 завершена --- tensor(1.0247, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 468 завершена --- tensor(1.2508, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 469 завершена --- tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 470 завершена --- tensor(1.5539, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 471 завершена --- tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 472 завершена --- tensor(1.1111, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 473 завершена --- tensor(1.1285, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 474 завершена --- tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 475 завершена --- tensor(1.0222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 476 завершена --- tensor(1.0526, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 477 завершена --- tensor(1.0332, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 478 завершена --- tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 479 завершена --- tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 480 завершена --- tensor(1.0054, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 481 завершена --- tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 482 завершена --- tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 483 завершена --- tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 484 завершена --- tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 485 завершена --- tensor(1.2370, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 486 завершена --- tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 487 завершена --- tensor(1.1162, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 488 завершена --- tensor(1.1323, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 489 завершена --- tensor(1.1407, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 490 завершена --- tensor(1.4817, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 491 завершена --- tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 492 завершена --- tensor(1.0083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 493 завершена --- tensor(1.3211, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 494 завершена --- tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 495 завершена --- tensor(1.3002, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 496 завершена --- tensor(1.0165, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 497 завершена --- tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 498 завершена --- tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 499 завершена --- tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 500 завершена --- tensor(1.1003, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 501 завершена --- tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 502 завершена --- tensor(1.1282, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 503 завершена --- tensor(0.8913, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 504 завершена --- tensor(1.1783, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 505 завершена --- tensor(1.2014, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 506 завершена --- tensor(1.1469, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 507 завершена --- tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 508 завершена --- tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 509 завершена --- tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 510 завершена --- tensor(1.1488, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 511 завершена --- tensor(1.2484, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 512 завершена --- tensor(1.2598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 513 завершена --- tensor(1.0942, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 514 завершена --- tensor(1.0167, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 515 завершена --- tensor(1.3557, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 516 завершена --- tensor(1.1382, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 517 завершена --- tensor(1.0413, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 518 завершена --- tensor(1.0000, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 519 завершена --- tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 520 завершена --- tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 521 завершена --- tensor(1.2083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 522 завершена --- tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 523 завершена --- tensor(1.1390, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 524 завершена --- tensor(1.1433, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 525 завершена --- tensor(1.2083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 526 завершена --- tensor(1.1795, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 527 завершена --- tensor(1.1176, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 528 завершена --- tensor(1.0627, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 529 завершена --- tensor(1.6531, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 530 завершена --- tensor(1.0519, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 531 завершена --- tensor(1.4575, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 532 завершена --- tensor(1.0801, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 533 завершена --- tensor(1.1345, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 534 завершена --- tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 535 завершена --- tensor(1.0303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 536 завершена --- tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 537 завершена --- tensor(1.0829, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 538 завершена --- tensor(1.0119, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 539 завершена --- tensor(1.1190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 540 завершена --- tensor(1.0220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 541 завершена --- tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 542 завершена --- tensor(1.1011, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 543 завершена --- tensor(1.0965, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 544 завершена --- tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 545 завершена --- tensor(1.1004, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 546 завершена --- tensor(1.0752, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 547 завершена --- tensor(1.0856, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 548 завершена --- tensor(1.0260, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 549 завершена --- tensor(1.1708, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 550 завершена --- tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 551 завершена --- tensor(1.0557, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 552 завершена --- tensor(1.5260, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 553 завершена --- tensor(1.0530, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 554 завершена --- tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 555 завершена --- tensor(1.0075, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 556 завершена --- tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 557 завершена --- tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 558 завершена --- tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 559 завершена --- tensor(1.0368, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 560 завершена --- tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 561 завершена --- tensor(1.4596, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 562 завершена --- tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 563 завершена --- tensor(1.0436, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 564 завершена --- tensor(1.3295, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 565 завершена --- tensor(1.2765, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 566 завершена --- tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 567 завершена --- tensor(1.0256, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 568 завершена --- tensor(1.3713, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 569 завершена --- tensor(0.9918, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 570 завершена --- tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 571 завершена --- tensor(1.1854, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 572 завершена --- tensor(1.0751, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 573 завершена --- tensor(1.0386, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 574 завершена --- tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 575 завершена --- tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 576 завершена --- tensor(1.0067, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 577 завершена --- tensor(1.4287, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 578 завершена --- tensor(1.0165, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 579 завершена --- tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 580 завершена --- tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 581 завершена --- tensor(1.0510, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 582 завершена --- tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 583 завершена --- tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 584 завершена --- tensor(1.2796, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 585 завершена --- tensor(1.2180, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 586 завершена --- tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 587 завершена --- tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 588 завершена --- tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 589 завершена --- tensor(1.0395, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 590 завершена --- tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 591 завершена --- tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 592 завершена --- tensor(1.0004, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 593 завершена --- tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 594 завершена --- tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 595 завершена --- tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 596 завершена --- tensor(1.1429, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 597 завершена --- tensor(1.2803, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 598 завершена --- tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 599 завершена --- tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 600 завершена --- tensor(1.0894, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 601 завершена --- tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 602 завершена --- tensor(0.9056, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 603 завершена --- tensor(0.9049, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 604 завершена --- tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 605 завершена --- tensor(0.8842, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 606 завершена --- tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 607 завершена --- tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 608 завершена --- tensor(0.8637, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 609 завершена --- tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 610 завершена --- tensor(0.8867, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 611 завершена --- tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 612 завершена --- tensor(0.8858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 613 завершена --- tensor(0.8355, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 614 завершена --- tensor(0.9707, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 615 завершена --- tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 616 завершена --- tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 617 завершена --- tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 618 завершена --- tensor(0.8813, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 619 завершена --- tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 620 завершена --- tensor(0.9018, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 621 завершена --- tensor(1.0592, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 622 завершена --- tensor(0.8919, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 623 завершена --- tensor(0.9011, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 624 завершена --- tensor(0.8506, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 625 завершена --- tensor(0.8819, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 626 завершена --- tensor(0.8149, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 627 завершена --- tensor(0.8798, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 628 завершена --- tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 629 завершена --- tensor(0.8365, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 630 завершена --- tensor(0.8435, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 631 завершена --- tensor(0.8611, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 632 завершена --- tensor(0.8953, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 633 завершена --- tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 634 завершена --- tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 635 завершена --- tensor(0.7956, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 636 завершена --- tensor(0.8706, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 637 завершена --- tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 638 завершена --- tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 639 завершена --- tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 640 завершена --- tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 641 завершена --- tensor(0.8823, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 642 завершена --- tensor(0.8189, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 643 завершена --- tensor(0.8164, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 644 завершена --- tensor(0.8330, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 645 завершена --- tensor(0.7838, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 646 завершена --- tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 647 завершена --- tensor(0.7487, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 648 завершена --- tensor(0.7568, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 649 завершена --- tensor(0.8135, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 650 завершена --- tensor(0.8554, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 651 завершена --- tensor(0.7388, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 652 завершена --- tensor(0.8668, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 653 завершена --- tensor(0.8448, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 654 завершена --- tensor(0.7559, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 655 завершена --- tensor(0.8824, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 656 завершена --- tensor(0.7507, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 657 завершена --- tensor(0.7811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 658 завершена --- tensor(0.7360, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 659 завершена --- tensor(0.9804, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 660 завершена --- tensor(0.7719, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 661 завершена --- tensor(0.7774, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 662 завершена --- tensor(1.1547, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 663 завершена --- tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 664 завершена --- tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 665 завершена --- tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 666 завершена --- tensor(0.7299, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 667 завершена --- tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 668 завершена --- tensor(0.8122, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 669 завершена --- tensor(1.5199, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 670 завершена --- tensor(1.1737, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 671 завершена --- tensor(0.8695, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 672 завершена --- tensor(0.8069, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 673 завершена --- tensor(0.8659, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 674 завершена --- tensor(0.8095, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 675 завершена --- tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 676 завершена --- tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 677 завершена --- tensor(0.7859, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 678 завершена --- tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 679 завершена --- tensor(0.7889, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 680 завершена --- tensor(0.8106, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 681 завершена --- tensor(0.7794, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 682 завершена --- tensor(0.7403, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 683 завершена --- tensor(0.8448, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 684 завершена --- tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 685 завершена --- tensor(0.7299, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 686 завершена --- tensor(0.7264, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 687 завершена --- tensor(0.7917, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 688 завершена --- tensor(1.4305, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 689 завершена --- tensor(0.6934, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 690 завершена --- tensor(0.7223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 691 завершена --- tensor(0.6889, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 692 завершена --- tensor(0.8735, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 693 завершена --- tensor(0.9054, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 694 завершена --- tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 695 завершена --- tensor(0.7071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 696 завершена --- tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 697 завершена --- tensor(1.2833, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 698 завершена --- tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 699 завершена --- tensor(1.3533, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 700 завершена --- tensor(0.8944, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 701 завершена --- tensor(0.8148, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 702 завершена --- tensor(0.8447, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 703 завершена --- tensor(0.8667, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 704 завершена --- tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 705 завершена --- tensor(1.0608, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 706 завершена --- tensor(0.7411, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 707 завершена --- tensor(0.8325, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 708 завершена --- tensor(0.7603, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 709 завершена --- tensor(0.8335, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 710 завершена --- tensor(0.7749, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 711 завершена --- tensor(1.3362, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 712 завершена --- tensor(0.7681, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 713 завершена --- tensor(0.7419, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 714 завершена --- tensor(0.7460, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 715 завершена --- tensor(0.8765, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 716 завершена --- tensor(0.7654, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 717 завершена --- tensor(0.7010, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 718 завершена --- tensor(0.6801, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 719 завершена --- tensor(0.7000, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 720 завершена --- tensor(0.8603, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 721 завершена --- tensor(1.3910, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 722 завершена --- tensor(1.1097, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 723 завершена --- tensor(0.8896, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 724 завершена --- tensor(0.7626, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 725 завершена --- tensor(0.7202, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 726 завершена --- tensor(0.8495, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 727 завершена --- tensor(0.8217, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 728 завершена --- tensor(0.7373, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 729 завершена --- tensor(0.7505, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 730 завершена --- tensor(0.6676, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 731 завершена --- tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 732 завершена --- tensor(0.7824, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 733 завершена --- tensor(0.7075, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 734 завершена --- tensor(0.7990, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 735 завершена --- tensor(0.8235, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 736 завершена --- tensor(0.7156, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 737 завершена --- tensor(0.7650, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 738 завершена --- tensor(0.6735, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 739 завершена --- tensor(0.7529, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 740 завершена --- tensor(0.7124, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 741 завершена --- tensor(0.6691, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 742 завершена --- tensor(0.6870, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 743 завершена --- tensor(0.6538, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 744 завершена --- tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 745 завершена --- tensor(0.6415, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 746 завершена --- tensor(0.6363, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 747 завершена --- tensor(0.6646, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 748 завершена --- tensor(0.6210, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 749 завершена --- tensor(1.0251, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 750 завершена --- tensor(0.8225, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 751 завершена --- tensor(1.0756, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 752 завершена --- tensor(0.6194, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 753 завершена --- tensor(0.9783, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 754 завершена --- tensor(1.0048, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 755 завершена --- tensor(0.6689, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 756 завершена --- tensor(0.7494, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 757 завершена --- tensor(1.1803, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 758 завершена --- tensor(0.6414, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 759 завершена --- tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 760 завершена --- tensor(0.7560, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 761 завершена --- tensor(1.0276, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 762 завершена --- tensor(0.6231, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 763 завершена --- tensor(0.8507, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 764 завершена --- tensor(0.8119, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 765 завершена --- tensor(0.8803, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 766 завершена --- tensor(0.6426, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 767 завершена --- tensor(0.7810, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 768 завершена --- tensor(0.6339, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 769 завершена --- tensor(0.6655, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 770 завершена --- tensor(0.5945, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 771 завершена --- tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 772 завершена --- tensor(1.0996, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 773 завершена --- tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 774 завершена --- tensor(1.4722, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 775 завершена --- tensor(0.8618, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 776 завершена --- tensor(0.6357, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 777 завершена --- tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 778 завершена --- tensor(1.3174, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 779 завершена --- tensor(0.7702, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 780 завершена --- tensor(0.8390, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 781 завершена --- tensor(0.8359, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 782 завершена --- tensor(0.7774, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 783 завершена --- tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 784 завершена --- tensor(0.6569, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 785 завершена --- tensor(0.6615, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 786 завершена --- tensor(0.7924, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 787 завершена --- tensor(0.7717, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 788 завершена --- tensor(0.7404, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 789 завершена --- tensor(0.7534, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 790 завершена --- tensor(0.6512, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 791 завершена --- tensor(0.6509, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 792 завершена --- tensor(0.6227, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 793 завершена --- tensor(0.6372, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 794 завершена --- tensor(0.6655, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 795 завершена --- tensor(1.0207, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 796 завершена --- tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 797 завершена --- tensor(0.7479, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 798 завершена --- tensor(0.7732, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 799 завершена --- tensor(0.6177, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 800 завершена --- tensor(0.6195, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 801 завершена --- tensor(0.6019, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 802 завершена --- tensor(0.7744, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 803 завершена --- tensor(0.7096, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 804 завершена --- tensor(0.7655, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 805 завершена --- tensor(0.8352, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 806 завершена --- tensor(0.7669, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 807 завершена --- tensor(0.8331, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 808 завершена --- tensor(1.1539, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 809 завершена --- tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 810 завершена --- tensor(1.4925, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 811 завершена --- tensor(0.6415, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 812 завершена --- tensor(0.7877, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 813 завершена --- tensor(0.7676, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 814 завершена --- tensor(0.7321, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 815 завершена --- tensor(0.6278, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 816 завершена --- tensor(1.2174, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 817 завершена --- tensor(0.7239, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 818 завершена --- tensor(0.7106, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 819 завершена --- tensor(0.6462, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 820 завершена --- tensor(0.6132, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 821 завершена --- tensor(0.7160, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 822 завершена --- tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 823 завершена --- tensor(0.6259, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 824 завершена --- tensor(0.7327, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 825 завершена --- tensor(0.5826, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 826 завершена --- tensor(0.8525, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 827 завершена --- tensor(0.5621, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 828 завершена --- tensor(0.7104, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 829 завершена --- tensor(0.8371, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 830 завершена --- tensor(0.5500, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 831 завершена --- tensor(0.7261, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 832 завершена --- tensor(0.6151, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 833 завершена --- tensor(1.2135, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 834 завершена --- tensor(0.7755, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 835 завершена --- tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 836 завершена --- tensor(0.9801, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 837 завершена --- tensor(0.7056, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 838 завершена --- tensor(0.5953, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 839 завершена --- tensor(0.7279, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 840 завершена --- tensor(0.5988, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 841 завершена --- tensor(0.8606, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 842 завершена --- tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 843 завершена --- tensor(0.5923, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 844 завершена --- tensor(0.7251, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 845 завершена --- tensor(0.6841, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 846 завершена --- tensor(0.5631, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 847 завершена --- tensor(0.6940, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 848 завершена --- tensor(0.5819, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 849 завершена --- tensor(0.6601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 850 завершена --- tensor(0.8451, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 851 завершена --- tensor(0.8303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 852 завершена --- tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 853 завершена --- tensor(0.6417, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 854 завершена --- tensor(0.7067, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 855 завершена --- tensor(0.6477, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 856 завершена --- tensor(0.7648, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 857 завершена --- tensor(0.7131, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 858 завершена --- tensor(0.7060, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 859 завершена --- tensor(0.6183, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 860 завершена --- tensor(0.6665, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 861 завершена --- tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 862 завершена --- tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 863 завершена --- tensor(0.8402, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 864 завершена --- tensor(0.6459, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 865 завершена --- tensor(0.6153, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 866 завершена --- tensor(0.5969, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 867 завершена --- tensor(0.7886, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 868 завершена --- tensor(0.6873, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 869 завершена --- tensor(0.6684, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 870 завершена --- tensor(0.5703, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 871 завершена --- tensor(0.6388, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 872 завершена --- tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 873 завершена --- tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 874 завершена --- tensor(0.6322, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 875 завершена --- tensor(0.6041, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 876 завершена --- tensor(0.7222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 877 завершена --- tensor(0.5928, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 878 завершена --- tensor(0.6096, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 879 завершена --- tensor(0.5981, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 880 завершена --- tensor(0.6597, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 881 завершена --- tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 882 завершена --- tensor(0.6034, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 883 завершена --- tensor(0.6148, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 884 завершена --- tensor(0.5819, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 885 завершена --- tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 886 завершена --- tensor(0.6147, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 887 завершена --- tensor(0.5821, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 888 завершена --- tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 889 завершена --- tensor(0.5725, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 890 завершена --- tensor(0.6190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 891 завершена --- tensor(0.5829, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 892 завершена --- tensor(0.5464, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 893 завершена --- tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 894 завершена --- tensor(1.4013, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 895 завершена --- tensor(0.6578, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 896 завершена --- tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 897 завершена --- tensor(0.5977, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 898 завершена --- tensor(0.6458, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 899 завершена --- tensor(1.3278, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 900 завершена --- tensor(0.5886, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 901 завершена --- tensor(1.1409, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 902 завершена --- tensor(0.6852, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 903 завершена --- tensor(0.5963, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 904 завершена --- tensor(0.6050, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 905 завершена --- tensor(0.6181, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 906 завершена --- tensor(0.7399, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 907 завершена --- tensor(0.6032, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 908 завершена --- tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 909 завершена --- tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 910 завершена --- tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 911 завершена --- tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 912 завершена --- tensor(0.6776, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 913 завершена --- tensor(0.6490, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 914 завершена --- tensor(0.6427, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 915 завершена --- tensor(0.6497, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 916 завершена --- tensor(0.6474, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 917 завершена --- tensor(0.6101, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 918 завершена --- tensor(0.6272, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 919 завершена --- tensor(0.5947, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 920 завершена --- tensor(1.2374, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 921 завершена --- tensor(1.2304, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 922 завершена --- tensor(0.8730, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 923 завершена --- tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 924 завершена --- tensor(0.6021, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 925 завершена --- tensor(0.6731, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 926 завершена --- tensor(0.6266, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 927 завершена --- tensor(0.6462, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 928 завершена --- tensor(0.5705, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 929 завершена --- tensor(0.6122, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 930 завершена --- tensor(0.5485, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 931 завершена --- tensor(0.6796, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 932 завершена --- tensor(0.5395, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 933 завершена --- tensor(0.6208, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 934 завершена --- tensor(0.7370, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 935 завершена --- tensor(0.6260, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 936 завершена --- tensor(0.8728, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 937 завершена --- tensor(0.5848, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 938 завершена --- tensor(0.5929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 939 завершена --- tensor(0.5910, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 940 завершена --- tensor(1.1521, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 941 завершена --- tensor(0.5314, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 942 завершена --- tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 943 завершена --- tensor(0.6885, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 944 завершена --- tensor(0.5498, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 945 завершена --- tensor(0.5863, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 946 завершена --- tensor(0.5826, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 947 завершена --- tensor(0.5902, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 948 завершена --- tensor(0.5288, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 949 завершена --- tensor(0.5527, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 950 завершена --- tensor(1.2410, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 951 завершена --- tensor(0.5769, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 952 завершена --- tensor(0.7048, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 953 завершена --- tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 954 завершена --- tensor(0.5343, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 955 завершена --- tensor(1.1045, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 956 завершена --- tensor(0.7434, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 957 завершена --- tensor(0.6014, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 958 завершена --- tensor(0.7766, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 959 завершена --- tensor(0.5211, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 960 завершена --- tensor(0.5689, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 961 завершена --- tensor(0.6582, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 962 завершена --- tensor(0.5754, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 963 завершена --- tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 964 завершена --- tensor(0.5982, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 965 завершена --- tensor(0.6175, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 966 завершена --- tensor(0.5497, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 967 завершена --- tensor(0.5130, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 968 завершена --- tensor(0.6064, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 969 завершена --- tensor(0.6123, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 970 завершена --- tensor(0.6066, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 971 завершена --- tensor(0.5370, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 972 завершена --- tensor(0.6172, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 973 завершена --- tensor(0.8389, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 974 завершена --- tensor(0.5358, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 975 завершена --- tensor(0.5683, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 976 завершена --- tensor(0.5712, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 977 завершена --- tensor(0.6111, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 978 завершена --- tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 979 завершена --- tensor(0.5692, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 980 завершена --- tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 981 завершена --- tensor(0.5553, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 982 завершена --- tensor(0.5478, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 983 завершена --- tensor(0.5337, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 984 завершена --- tensor(0.5667, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 985 завершена --- tensor(0.5592, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 986 завершена --- tensor(0.5379, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 987 завершена --- tensor(0.5182, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 988 завершена --- tensor(1.2931, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 989 завершена --- tensor(0.5386, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 990 завершена --- tensor(0.5373, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 991 завершена --- tensor(0.5573, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 992 завершена --- tensor(0.5201, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 993 завершена --- tensor(0.5117, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 994 завершена --- tensor(0.5460, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 995 завершена --- tensor(0.4733, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 996 завершена --- tensor(0.5073, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 997 завершена --- tensor(0.5491, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 998 завершена --- tensor(0.4735, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 999 завершена --- tensor(0.6171, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1000 завершена --- tensor(0.4938, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1001 завершена --- tensor(0.4988, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1002 завершена --- tensor(0.5835, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1003 завершена --- tensor(0.8634, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1004 завершена --- tensor(0.6157, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1005 завершена --- tensor(0.7594, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1006 завершена --- tensor(0.7720, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1007 завершена --- tensor(0.5619, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1008 завершена --- tensor(0.7637, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1009 завершена --- tensor(1.1264, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1010 завершена --- tensor(1.0924, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1011 завершена --- tensor(0.6020, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1012 завершена --- tensor(1.0890, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1013 завершена --- tensor(0.6014, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1014 завершена --- tensor(0.5941, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1015 завершена --- tensor(0.6058, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1016 завершена --- tensor(0.5639, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1017 завершена --- tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1018 завершена --- tensor(0.5751, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1019 завершена --- tensor(0.5805, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1020 завершена --- tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1021 завершена --- tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1022 завершена --- tensor(0.6033, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1023 завершена --- tensor(0.5570, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1024 завершена --- tensor(0.8199, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1025 завершена --- tensor(0.5785, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1026 завершена --- tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1027 завершена --- tensor(0.5908, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1028 завершена --- tensor(0.6269, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1029 завершена --- tensor(0.5763, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1030 завершена --- tensor(0.5442, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1031 завершена --- tensor(0.5462, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1032 завершена --- tensor(0.6003, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1033 завершена --- tensor(1.0618, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1034 завершена --- tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1035 завершена --- tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1036 завершена --- tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1037 завершена --- tensor(0.5961, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1038 завершена --- tensor(1.0897, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1039 завершена --- tensor(0.5996, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1040 завершена --- tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1041 завершена --- tensor(0.5794, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1042 завершена --- tensor(0.5727, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1043 завершена --- tensor(0.5722, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1044 завершена --- tensor(0.6047, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1045 завершена --- tensor(0.5724, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1046 завершена --- tensor(0.5798, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1047 завершена --- tensor(0.8488, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1048 завершена --- tensor(0.5800, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1049 завершена --- tensor(0.5903, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1050 завершена --- tensor(0.6030, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1051 завершена --- tensor(0.5514, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1052 завершена --- tensor(0.5290, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1053 завершена --- tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1054 завершена --- tensor(0.5406, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1055 завершена --- tensor(0.5635, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1056 завершена --- tensor(0.5320, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1057 завершена --- tensor(0.5882, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1058 завершена --- tensor(0.6071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1059 завершена --- tensor(0.5196, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1060 завершена --- tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1061 завершена --- tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1062 завершена --- tensor(0.7381, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1063 завершена --- tensor(0.5599, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1064 завершена --- tensor(0.4969, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1065 завершена --- tensor(0.7670, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1066 завершена --- tensor(0.5571, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1067 завершена --- tensor(0.5793, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1068 завершена --- tensor(0.5585, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1069 завершена --- tensor(0.6766, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1070 завершена --- tensor(0.7721, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1071 завершена --- tensor(0.5055, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1072 завершена --- tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1073 завершена --- tensor(0.5246, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1074 завершена --- tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1075 завершена --- tensor(0.5140, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1076 завершена --- tensor(0.5303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1077 завершена --- tensor(0.5401, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1078 завершена --- tensor(0.5928, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1079 завершена --- tensor(0.7074, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1080 завершена --- tensor(0.5270, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1081 завершена --- tensor(0.5049, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1082 завершена --- tensor(0.5409, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1083 завершена --- tensor(0.5301, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1084 завершена --- tensor(0.4995, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1085 завершена --- tensor(0.5106, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1086 завершена --- tensor(0.5457, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1087 завершена --- tensor(0.5315, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1088 завершена --- tensor(0.5203, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1089 завершена --- tensor(0.4879, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1090 завершена --- tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1091 завершена --- tensor(0.5168, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1092 завершена --- tensor(0.5010, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1093 завершена --- tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1094 завершена --- tensor(0.5171, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1095 завершена --- tensor(0.5003, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1096 завершена --- tensor(0.7455, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1097 завершена --- tensor(0.4566, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1098 завершена --- tensor(0.4927, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1099 завершена --- tensor(0.5149, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1100 завершена --- tensor(0.4932, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1101 завершена --- tensor(0.5030, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1102 завершена --- tensor(1.1549, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1103 завершена --- tensor(0.5098, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1104 завершена --- tensor(0.6604, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1105 завершена --- tensor(0.7681, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1106 завершена --- tensor(0.4717, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1107 завершена --- tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1108 завершена --- tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1109 завершена --- tensor(0.5280, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1110 завершена --- tensor(0.4992, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1111 завершена --- tensor(0.8980, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1112 завершена --- tensor(0.4947, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1113 завершена --- tensor(0.4933, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1114 завершена --- tensor(0.5811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1115 завершена --- tensor(0.5510, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1116 завершена --- tensor(0.5425, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1117 завершена --- tensor(0.5233, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1118 завершена --- tensor(0.5122, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1119 завершена --- tensor(0.5180, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1120 завершена --- tensor(0.5059, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1121 завершена --- tensor(1.2739, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1122 завершена --- tensor(0.5109, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1123 завершена --- tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1124 завершена --- tensor(0.5813, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1125 завершена --- tensor(0.5483, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1126 завершена --- tensor(0.5606, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1127 завершена --- tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1128 завершена --- tensor(0.7895, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1129 завершена --- tensor(0.5205, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1130 завершена --- tensor(0.5816, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1131 завершена --- tensor(0.5358, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1132 завершена --- tensor(0.5363, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1133 завершена --- tensor(0.5679, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1134 завершена --- tensor(0.7140, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1135 завершена --- tensor(0.5708, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1136 завершена --- tensor(0.5333, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1137 завершена --- tensor(0.5552, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1138 завершена --- tensor(0.7847, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1139 завершена --- tensor(0.7909, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1140 завершена --- tensor(0.5484, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1141 завершена --- tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1142 завершена --- tensor(0.5244, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1143 завершена --- tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1144 завершена --- tensor(0.5545, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1145 завершена --- tensor(0.5217, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1146 завершена --- tensor(0.6846, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1147 завершена --- tensor(0.5206, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1148 завершена --- tensor(0.5418, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1149 завершена --- tensor(0.5112, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1150 завершена --- tensor(0.5083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1151 завершена --- tensor(0.5133, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1152 завершена --- tensor(0.5464, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1153 завершена --- tensor(0.8077, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1154 завершена --- tensor(0.6985, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1155 завершена --- tensor(0.5209, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1156 завершена --- tensor(0.6511, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1157 завершена --- tensor(0.5316, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1158 завершена --- tensor(0.5191, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1159 завершена --- tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1160 завершена --- tensor(0.5172, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1161 завершена --- tensor(0.6198, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1162 завершена --- tensor(0.5998, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1163 завершена --- tensor(0.4784, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1164 завершена --- tensor(0.5154, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1165 завершена --- tensor(0.5574, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1166 завершена --- tensor(0.8439, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1167 завершена --- tensor(0.5010, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1168 завершена --- tensor(0.4887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1169 завершена --- tensor(0.4927, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1170 завершена --- tensor(0.4956, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1171 завершена --- tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1172 завершена --- tensor(0.4723, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1173 завершена --- tensor(0.4737, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1174 завершена --- tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1175 завершена --- tensor(0.5136, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1176 завершена --- tensor(0.5032, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1177 завершена --- tensor(1.1571, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1178 завершена --- tensor(0.4729, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1179 завершена --- tensor(0.4693, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1180 завершена --- tensor(0.8387, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1181 завершена --- tensor(0.6247, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1182 завершена --- tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1183 завершена --- tensor(0.5676, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1184 завершена --- tensor(0.5739, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1185 завершена --- tensor(0.4913, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1186 завершена --- tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1187 завершена --- tensor(0.5191, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1188 завершена --- tensor(0.5618, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1189 завершена --- tensor(0.5340, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1190 завершена --- tensor(0.5422, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1191 завершена --- tensor(0.5413, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1192 завершена --- tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1193 завершена --- tensor(0.5393, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1194 завершена --- tensor(0.5198, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1195 завершена --- tensor(0.4885, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1196 завершена --- tensor(0.5328, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1197 завершена --- tensor(1.1712, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1198 завершена --- tensor(0.4942, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1199 завершена --- tensor(0.5908, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1200 завершена --- tensor(0.8036, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1201 завершена --- tensor(0.4777, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1202 завершена --- tensor(0.5204, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1203 завершена --- tensor(0.5323, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1204 завершена --- tensor(0.7307, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1205 завершена --- tensor(0.5662, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1206 завершена --- tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1207 завершена --- tensor(0.5362, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1208 завершена --- tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1209 завершена --- tensor(0.5737, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1210 завершена --- tensor(0.4985, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1211 завершена --- tensor(0.4979, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1212 завершена --- tensor(0.5224, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1213 завершена --- tensor(0.5363, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1214 завершена --- tensor(0.4917, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1215 завершена --- tensor(0.5175, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1216 завершена --- tensor(0.4884, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1217 завершена --- tensor(0.8759, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1218 завершена --- tensor(0.4913, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1219 завершена --- tensor(0.5612, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1220 завершена --- tensor(0.5314, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1221 завершена --- tensor(0.4763, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1222 завершена --- tensor(0.5115, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1223 завершена --- tensor(1.0646, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1224 завершена --- tensor(0.4835, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1225 завершена --- tensor(0.4811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1226 завершена --- tensor(0.4904, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1227 завершена --- tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1228 завершена --- tensor(0.6494, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1229 завершена --- tensor(0.4997, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1230 завершена --- tensor(0.5168, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1231 завершена --- tensor(0.4821, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1232 завершена --- tensor(0.6038, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1233 завершена --- tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1234 завершена --- tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1235 завершена --- tensor(0.7638, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1236 завершена --- tensor(0.5143, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1237 завершена --- tensor(0.5206, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1238 завершена --- tensor(0.5296, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1239 завершена --- tensor(0.5232, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1240 завершена --- tensor(0.5093, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1241 завершена --- tensor(0.5287, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1242 завершена --- tensor(0.5669, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1243 завершена --- tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1244 завершена --- tensor(0.5022, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1245 завершена --- tensor(0.5550, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1246 завершена --- tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1247 завершена --- tensor(0.5168, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1248 завершена --- tensor(0.5081, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1249 завершена --- tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1250 завершена --- tensor(0.4862, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1251 завершена --- tensor(0.4834, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1252 завершена --- tensor(0.5127, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1253 завершена --- tensor(0.4602, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1254 завершена --- tensor(0.4712, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1255 завершена --- tensor(0.7139, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1256 завершена --- tensor(0.4678, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1257 завершена --- tensor(0.4588, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1258 завершена --- tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1259 завершена --- tensor(1.1915, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1260 завершена --- tensor(0.4618, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1261 завершена --- tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1262 завершена --- tensor(0.6161, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1263 завершена --- tensor(0.4598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1264 завершена --- tensor(0.4472, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1265 завершена --- tensor(0.4891, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1266 завершена --- tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1267 завершена --- tensor(0.5122, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1268 завершена --- tensor(0.4517, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1269 завершена --- tensor(0.4867, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1270 завершена --- tensor(0.5341, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1271 завершена --- tensor(0.4410, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1272 завершена --- tensor(0.4927, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1273 завершена --- tensor(0.5353, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1274 завершена --- tensor(0.4695, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1275 завершена --- tensor(0.4894, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1276 завершена --- tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1277 завершена --- tensor(0.4328, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1278 завершена --- tensor(1.0081, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1279 завершена --- tensor(0.4502, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1280 завершена --- tensor(0.5113, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1281 завершена --- tensor(0.5062, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1282 завершена --- tensor(0.8130, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1283 завершена --- tensor(0.5137, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1284 завершена --- tensor(0.5058, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1285 завершена --- tensor(0.4741, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1286 завершена --- tensor(0.4584, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1287 завершена --- tensor(0.4566, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1288 завершена --- tensor(0.5116, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1289 завершена --- tensor(0.4919, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1290 завершена --- tensor(0.5240, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1291 завершена --- tensor(0.5064, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1292 завершена --- tensor(0.5001, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1293 завершена --- tensor(0.4727, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1294 завершена --- tensor(0.5020, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1295 завершена --- tensor(0.4647, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1296 завершена --- tensor(0.4781, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1297 завершена --- tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1298 завершена --- tensor(0.4835, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1299 завершена --- tensor(0.6155, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1300 завершена --- tensor(0.6744, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1301 завершена --- tensor(0.4284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1302 завершена --- tensor(1.2328, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1303 завершена --- tensor(0.6208, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1304 завершена --- tensor(0.4619, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1305 завершена --- tensor(0.5090, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1306 завершена --- tensor(0.5030, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1307 завершена --- tensor(0.5063, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1308 завершена --- tensor(0.5159, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1309 завершена --- tensor(0.5179, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1310 завершена --- tensor(0.6897, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1311 завершена --- tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1312 завершена --- tensor(0.6596, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1313 завершена --- tensor(0.4988, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1314 завершена --- tensor(0.4815, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1315 завершена --- tensor(0.6578, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1316 завершена --- tensor(0.4636, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1317 завершена --- tensor(0.4735, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1318 завершена --- tensor(0.5086, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1319 завершена --- tensor(0.4485, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1320 завершена --- tensor(0.4691, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1321 завершена --- tensor(1.1715, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1322 завершена --- tensor(0.4287, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1323 завершена --- tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1324 завершена --- tensor(0.4766, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1325 завершена --- tensor(0.4650, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1326 завершена --- tensor(0.5251, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1327 завершена --- tensor(0.5132, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1328 завершена --- tensor(0.4887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1329 завершена --- tensor(0.4503, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1330 завершена --- tensor(0.5420, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1331 завершена --- tensor(0.7803, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1332 завершена --- tensor(0.4401, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1333 завершена --- tensor(0.5391, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1334 завершена --- tensor(0.5152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1335 завершена --- tensor(0.4730, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1336 завершена --- tensor(0.6142, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1337 завершена --- tensor(0.4816, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1338 завершена --- tensor(0.5153, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1339 завершена --- tensor(0.4986, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1340 завершена --- tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1341 завершена --- tensor(0.4747, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1342 завершена --- tensor(0.4684, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1343 завершена --- tensor(0.6246, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1344 завершена --- tensor(0.5314, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1345 завершена --- tensor(1.1124, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1346 завершена --- tensor(0.5001, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1347 завершена --- tensor(0.5008, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1348 завершена --- tensor(0.8812, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1349 завершена --- tensor(0.4747, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1350 завершена --- tensor(0.4783, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1351 завершена --- tensor(0.5620, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1352 завершена --- tensor(0.4617, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1353 завершена --- tensor(0.4506, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1354 завершена --- tensor(0.4765, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1355 завершена --- tensor(0.5186, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1356 завершена --- tensor(0.4648, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1357 завершена --- tensor(0.5579, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1358 завершена --- tensor(0.5854, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1359 завершена --- tensor(1.0043, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1360 завершена --- tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1361 завершена --- tensor(0.4588, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1362 завершена --- tensor(0.4682, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1363 завершена --- tensor(0.5165, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1364 завершена --- tensor(0.4469, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1365 завершена --- tensor(0.5348, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1366 завершена --- tensor(0.4963, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1367 завершена --- tensor(0.4632, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1368 завершена --- tensor(0.7171, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1369 завершена --- tensor(0.5253, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1370 завершена --- tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1371 завершена --- tensor(0.5531, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1372 завершена --- tensor(0.4624, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1373 завершена --- tensor(0.4654, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1374 завершена --- tensor(0.4356, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1375 завершена --- tensor(0.4870, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1376 завершена --- tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1377 завершена --- tensor(0.7187, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1378 завершена --- tensor(0.6986, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1379 завершена --- tensor(0.5524, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1380 завершена --- tensor(0.5301, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1381 завершена --- tensor(0.5212, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1382 завершена --- tensor(0.4757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1383 завершена --- tensor(0.4929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1384 завершена --- tensor(0.4841, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1385 завершена --- tensor(0.5519, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1386 завершена --- tensor(0.4637, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1387 завершена --- tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1388 завершена --- tensor(0.4604, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1389 завершена --- tensor(0.4569, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1390 завершена --- tensor(0.4418, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1391 завершена --- tensor(0.4468, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1392 завершена --- tensor(0.4303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1393 завершена --- tensor(0.4811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1394 завершена --- tensor(0.4392, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1395 завершена --- tensor(0.4193, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1396 завершена --- tensor(0.4166, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1397 завершена --- tensor(0.5623, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1398 завершена --- tensor(0.6940, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1399 завершена --- tensor(0.4382, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1400 завершена --- tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1401 завершена --- tensor(0.4399, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1402 завершена --- tensor(0.4718, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1403 завершена --- tensor(0.4769, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1404 завершена --- tensor(0.4832, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1405 завершена --- tensor(0.4371, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1406 завершена --- tensor(0.4392, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1407 завершена --- tensor(0.4240, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1408 завершена --- tensor(0.4560, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1409 завершена --- tensor(0.4614, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1410 завершена --- tensor(0.4620, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1411 завершена --- tensor(0.4384, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1412 завершена --- tensor(0.4259, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1413 завершена --- tensor(0.4405, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1414 завершена --- tensor(0.4235, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1415 завершена --- tensor(0.7294, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1416 завершена --- tensor(0.4068, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1417 завершена --- tensor(0.4694, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1418 завершена --- tensor(0.4130, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1419 завершена --- tensor(0.5270, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1420 завершена --- tensor(0.4292, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1421 завершена --- tensor(0.4182, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1422 завершена --- tensor(0.4531, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1423 завершена --- tensor(0.8677, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1424 завершена --- tensor(0.4299, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1425 завершена --- tensor(1.0604, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1426 завершена --- tensor(0.6329, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1427 завершена --- tensor(0.4472, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1428 завершена --- tensor(0.4296, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1429 завершена --- tensor(0.4836, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1430 завершена --- tensor(0.4348, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1431 завершена --- tensor(0.7753, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1432 завершена --- tensor(0.7278, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1433 завершена --- tensor(0.4516, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1434 завершена --- tensor(0.4348, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1435 завершена --- tensor(0.4970, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1436 завершена --- tensor(0.4612, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1437 завершена --- tensor(0.4343, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1438 завершена --- tensor(0.4443, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1439 завершена --- tensor(0.6431, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1440 завершена --- tensor(0.4294, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1441 завершена --- tensor(0.4887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1442 завершена --- tensor(0.4568, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1443 завершена --- tensor(0.4827, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1444 завершена --- tensor(0.4334, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1445 завершена --- tensor(0.4327, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1446 завершена --- tensor(0.7285, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1447 завершена --- tensor(0.4465, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1448 завершена --- tensor(0.5607, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1449 завершена --- tensor(0.6124, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1450 завершена --- tensor(0.6025, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1451 завершена --- tensor(0.4793, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1452 завершена --- tensor(0.4824, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1453 завершена --- tensor(0.4357, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1454 завершена --- tensor(0.4618, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1455 завершена --- tensor(0.4475, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1456 завершена --- tensor(0.4694, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1457 завершена --- tensor(0.4652, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1458 завершена --- tensor(0.4592, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1459 завершена --- tensor(0.4355, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1460 завершена --- tensor(0.4397, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1461 завершена --- tensor(0.8337, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1462 завершена --- tensor(0.5131, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1463 завершена --- tensor(0.7938, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1464 завершена --- tensor(0.4581, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1465 завершена --- tensor(0.4447, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1466 завершена --- tensor(1.0978, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1467 завершена --- tensor(0.5165, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1468 завершена --- tensor(0.4743, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1469 завершена --- tensor(0.4862, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1470 завершена --- tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1471 завершена --- tensor(0.4894, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1472 завершена --- tensor(0.6777, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1473 завершена --- tensor(0.5652, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1474 завершена --- tensor(0.4693, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1475 завершена --- tensor(0.5115, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1476 завершена --- tensor(0.4962, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1477 завершена --- tensor(0.4437, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1478 завершена --- tensor(0.6826, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1479 завершена --- tensor(0.4964, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1480 завершена --- tensor(0.4598, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1481 завершена --- tensor(1.2202, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1482 завершена --- tensor(0.4635, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1483 завершена --- tensor(0.5104, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1484 завершена --- tensor(1.1218, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1485 завершена --- tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1486 завершена --- tensor(0.8425, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1487 завершена --- tensor(0.5033, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1488 завершена --- tensor(0.4933, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1489 завершена --- tensor(0.5113, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1490 завершена --- tensor(0.4943, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1491 завершена --- tensor(0.5058, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1492 завершена --- tensor(0.5065, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1493 завершена --- tensor(0.4906, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1494 завершена --- tensor(1.0974, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1495 завершена --- tensor(0.4886, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1496 завершена --- tensor(0.4798, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1497 завершена --- tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1498 завершена --- tensor(0.4745, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1499 завершена --- tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1500 завершена --- tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1501 завершена --- tensor(0.4625, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1502 завершена --- tensor(1.0142, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1503 завершена --- tensor(0.4566, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1504 завершена --- tensor(0.4733, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1505 завершена --- tensor(0.7444, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1506 завершена --- tensor(0.4647, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1507 завершена --- tensor(0.5326, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1508 завершена --- tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1509 завершена --- tensor(0.4462, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1510 завершена --- tensor(0.5560, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1511 завершена --- tensor(0.4900, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1512 завершена --- tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1513 завершена --- tensor(0.5623, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1514 завершена --- tensor(0.5814, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1515 завершена --- tensor(0.5014, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1516 завершена --- tensor(0.5039, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1517 завершена --- tensor(0.4991, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1518 завершена --- tensor(0.4776, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1519 завершена --- tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1520 завершена --- tensor(0.4978, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1521 завершена --- tensor(0.4702, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1522 завершена --- tensor(0.5546, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1523 завершена --- tensor(0.6221, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1524 завершена --- tensor(0.8021, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1525 завершена --- tensor(0.5183, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1526 завершена --- tensor(0.5696, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1527 завершена --- tensor(0.6953, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1528 завершена --- tensor(0.5220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1529 завершена --- tensor(0.4786, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1530 завершена --- tensor(0.5382, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1531 завершена --- tensor(0.5133, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1532 завершена --- tensor(0.5047, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1533 завершена --- tensor(0.4901, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1534 завершена --- tensor(0.5728, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1535 завершена --- tensor(0.4850, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1536 завершена --- tensor(0.4576, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1537 завершена --- tensor(0.6455, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1538 завершена --- tensor(0.5776, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1539 завершена --- tensor(0.4557, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1540 завершена --- tensor(0.4847, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1541 завершена --- tensor(0.5183, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1542 завершена --- tensor(0.6635, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1543 завершена --- tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1544 завершена --- tensor(0.5154, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1545 завершена --- tensor(0.4809, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1546 завершена --- tensor(0.4832, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1547 завершена --- tensor(0.4717, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1548 завершена --- tensor(0.4882, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1549 завершена --- tensor(0.5089, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1550 завершена --- tensor(0.4948, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1551 завершена --- tensor(0.4704, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1552 завершена --- tensor(0.4578, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1553 завершена --- tensor(0.5284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1554 завершена --- tensor(0.4671, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1555 завершена --- tensor(0.4461, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1556 завершена --- tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1557 завершена --- tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1558 завершена --- tensor(0.4431, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1559 завершена --- tensor(0.4746, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1560 завершена --- tensor(0.4776, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1561 завершена --- tensor(0.4685, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1562 завершена --- tensor(0.4504, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1563 завершена --- tensor(0.4268, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1564 завершена --- tensor(1.0981, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1565 завершена --- tensor(0.5640, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1566 завершена --- tensor(0.4402, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1567 завершена --- tensor(0.4386, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1568 завершена --- tensor(0.5094, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1569 завершена --- tensor(0.4820, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1570 завершена --- tensor(1.0367, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1571 завершена --- tensor(0.5715, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1572 завершена --- tensor(0.4628, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1573 завершена --- tensor(0.7850, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1574 завершена --- tensor(0.4715, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1575 завершена --- tensor(0.4657, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1576 завершена --- tensor(0.5011, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1577 завершена --- tensor(0.6758, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1578 завершена --- tensor(0.4449, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1579 завершена --- tensor(0.4997, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1580 завершена --- tensor(0.6382, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1581 завершена --- tensor(0.4691, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1582 завершена --- tensor(0.4568, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1583 завершена --- tensor(0.5099, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1584 завершена --- tensor(1.0742, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1585 завершена --- tensor(0.4649, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1586 завершена --- tensor(0.4700, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1587 завершена --- tensor(0.4351, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1588 завершена --- tensor(0.6107, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1589 завершена --- tensor(0.4757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1590 завершена --- tensor(0.4661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1591 завершена --- tensor(0.4957, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1592 завершена --- tensor(0.4335, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1593 завершена --- tensor(0.8338, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1594 завершена --- tensor(0.4294, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1595 завершена --- tensor(0.4667, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1596 завершена --- tensor(1.1071, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1597 завершена --- tensor(0.4949, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1598 завершена --- tensor(0.4934, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1599 завершена --- tensor(0.4704, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1600 завершена --- tensor(0.4603, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1601 завершена --- tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1602 завершена --- tensor(0.4739, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1603 завершена --- tensor(0.4416, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1604 завершена --- tensor(0.4807, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1605 завершена --- tensor(0.4601, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1606 завершена --- tensor(0.4593, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1607 завершена --- tensor(0.4515, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1608 завершена --- tensor(0.4483, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1609 завершена --- tensor(0.4609, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1610 завершена --- tensor(0.6257, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1611 завершена --- tensor(0.4635, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1612 завершена --- tensor(0.5400, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1613 завершена --- tensor(0.4849, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1614 завершена --- tensor(0.4430, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1615 завершена --- tensor(0.4459, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1616 завершена --- tensor(0.4541, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1617 завершена --- tensor(0.4229, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1618 завершена --- tensor(0.4152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1619 завершена --- tensor(0.6561, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1620 завершена --- tensor(0.4242, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1621 завершена --- tensor(0.8053, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1622 завершена --- tensor(0.7661, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1623 завершена --- tensor(0.4501, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1624 завершена --- tensor(0.5098, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1625 завершена --- tensor(0.4582, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1626 завершена --- tensor(0.8461, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1627 завершена --- tensor(0.5313, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1628 завершена --- tensor(0.8399, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1629 завершена --- tensor(0.4907, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1630 завершена --- tensor(0.4793, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1631 завершена --- tensor(0.4681, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1632 завершена --- tensor(0.4455, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1633 завершена --- tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1634 завершена --- tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1635 завершена --- tensor(0.4397, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1636 завершена --- tensor(0.5343, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1637 завершена --- tensor(0.4350, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1638 завершена --- tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1639 завершена --- tensor(0.4514, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1640 завершена --- tensor(0.4430, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1641 завершена --- tensor(0.4244, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1642 завершена --- tensor(0.4223, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1643 завершена --- tensor(0.4372, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1644 завершена --- tensor(0.4656, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1645 завершена --- tensor(0.4887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1646 завершена --- tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1647 завершена --- tensor(0.4162, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1648 завершена --- tensor(0.4836, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1649 завершена --- tensor(0.4543, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1650 завершена --- tensor(0.4470, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1651 завершена --- tensor(0.4586, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1652 завершена --- tensor(0.4195, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1653 завершена --- tensor(0.4148, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1654 завершена --- tensor(0.4370, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1655 завершена --- tensor(0.5950, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1656 завершена --- tensor(0.3911, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1657 завершена --- tensor(0.3847, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1658 завершена --- tensor(0.4662, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1659 завершена --- tensor(0.4113, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1660 завершена --- tensor(0.3953, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1661 завершена --- tensor(0.4453, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1662 завершена --- tensor(0.3882, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1663 завершена --- tensor(0.7914, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1664 завершена --- tensor(0.4493, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1665 завершена --- tensor(0.3959, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1666 завершена --- tensor(0.4446, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1667 завершена --- tensor(0.4144, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1668 завершена --- tensor(0.5430, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1669 завершена --- tensor(0.3936, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1670 завершена --- tensor(0.5080, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1671 завершена --- tensor(0.3730, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1672 завершена --- tensor(0.4494, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1673 завершена --- tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1674 завершена --- tensor(0.4650, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1675 завершена --- tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1676 завершена --- tensor(0.4255, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1677 завершена --- tensor(0.4409, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1678 завершена --- tensor(0.4341, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1679 завершена --- tensor(0.4201, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1680 завершена --- tensor(0.4579, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1681 завершена --- tensor(0.4190, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1682 завершена --- tensor(0.4205, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1683 завершена --- tensor(0.4778, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1684 завершена --- tensor(0.4288, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1685 завершена --- tensor(1.0902, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1686 завершена --- tensor(0.4846, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1687 завершена --- tensor(0.4425, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1688 завершена --- tensor(0.4254, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1689 завершена --- tensor(0.4220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1690 завершена --- tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1691 завершена --- tensor(0.4566, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1692 завершена --- tensor(0.4562, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1693 завершена --- tensor(0.4355, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1694 завершена --- tensor(0.4381, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1695 завершена --- tensor(0.4374, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1696 завершена --- tensor(0.4145, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1697 завершена --- tensor(0.4225, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1698 завершена --- tensor(0.4195, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1699 завершена --- tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1700 завершена --- tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1701 завершена --- tensor(0.4115, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1702 завершена --- tensor(0.4509, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1703 завершена --- tensor(0.8142, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1704 завершена --- tensor(0.4068, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1705 завершена --- tensor(0.4175, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1706 завершена --- tensor(0.4004, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1707 завершена --- tensor(0.4320, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1708 завершена --- tensor(0.4220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1709 завершена --- tensor(0.4512, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1710 завершена --- tensor(0.4514, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1711 завершена --- tensor(0.5155, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1712 завершена --- tensor(0.4114, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1713 завершена --- tensor(0.4335, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1714 завершена --- tensor(0.4273, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1715 завершена --- tensor(0.4062, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1716 завершена --- tensor(0.4284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1717 завершена --- tensor(0.4315, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1718 завершена --- tensor(0.4052, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1719 завершена --- tensor(0.3973, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1720 завершена --- tensor(0.3928, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1721 завершена --- tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1722 завершена --- tensor(0.8964, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1723 завершена --- tensor(0.4251, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1724 завершена --- tensor(0.4284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1725 завершена --- tensor(0.4369, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1726 завершена --- tensor(0.4682, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1727 завершена --- tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1728 завершена --- tensor(0.4464, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1729 завершена --- tensor(0.4579, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1730 завершена --- tensor(0.4501, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1731 завершена --- tensor(0.4373, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1732 завершена --- tensor(0.4119, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1733 завершена --- tensor(0.4671, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1734 завершена --- tensor(0.4052, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1735 завершена --- tensor(0.4492, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1736 завершена --- tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1737 завершена --- tensor(0.7510, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1738 завершена --- tensor(0.4548, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1739 завершена --- tensor(0.4168, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1740 завершена --- tensor(0.6684, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1741 завершена --- tensor(0.3973, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1742 завершена --- tensor(0.6850, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1743 завершена --- tensor(1.0286, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1744 завершена --- tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1745 завершена --- tensor(0.4853, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1746 завершена --- tensor(0.4735, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1747 завершена --- tensor(0.4798, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1748 завершена --- tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1749 завершена --- tensor(0.6160, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1750 завершена --- tensor(0.4866, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1751 завершена --- tensor(0.4428, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1752 завершена --- tensor(0.5275, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1753 завершена --- tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1754 завершена --- tensor(0.4380, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1755 завершена --- tensor(0.4919, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1756 завершена --- tensor(0.6078, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1757 завершена --- tensor(0.8008, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1758 завершена --- tensor(0.7173, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1759 завершена --- tensor(0.5154, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1760 завершена --- tensor(0.4321, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1761 завершена --- tensor(0.5263, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1762 завершена --- tensor(0.4698, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1763 завершена --- tensor(1.0513, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1764 завершена --- tensor(0.6235, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1765 завершена --- tensor(1.0210, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1766 завершена --- tensor(0.6245, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1767 завершена --- tensor(0.4587, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1768 завершена --- tensor(0.5590, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1769 завершена --- tensor(1.1757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1770 завершена --- tensor(0.4517, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1771 завершена --- tensor(0.6078, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1772 завершена --- tensor(0.5044, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1773 завершена --- tensor(0.5616, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1774 завершена --- tensor(0.8678, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1775 завершена --- tensor(0.5754, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1776 завершена --- tensor(0.5076, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1777 завершена --- tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1778 завершена --- tensor(0.5237, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1779 завершена --- tensor(0.5023, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1780 завершена --- tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1781 завершена --- tensor(0.4454, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1782 завершена --- tensor(0.5152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1783 завершена --- tensor(0.4137, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1784 завершена --- tensor(0.5162, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1785 завершена --- tensor(0.4166, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1786 завершена --- tensor(0.5631, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1787 завершена --- tensor(0.5011, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1788 завершена --- tensor(0.4873, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1789 завершена --- tensor(0.8692, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1790 завершена --- tensor(0.4743, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1791 завершена --- tensor(0.4552, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1792 завершена --- tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1793 завершена --- tensor(0.4355, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1794 завершена --- tensor(0.4629, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1795 завершена --- tensor(0.5916, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1796 завершена --- tensor(0.4381, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1797 завершена --- tensor(0.4411, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1798 завершена --- tensor(0.4467, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1799 завершена --- tensor(0.4749, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1800 завершена --- tensor(0.4258, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1801 завершена --- tensor(0.5677, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1802 завершена --- tensor(0.6814, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1803 завершена --- tensor(0.4351, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1804 завершена --- tensor(0.4745, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1805 завершена --- tensor(0.4572, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1806 завершена --- tensor(0.4109, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1807 завершена --- tensor(0.4970, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1808 завершена --- tensor(0.4384, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1809 завершена --- tensor(1.0630, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1810 завершена --- tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1811 завершена --- tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1812 завершена --- tensor(0.4184, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1813 завершена --- tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1814 завершена --- tensor(0.4802, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1815 завершена --- tensor(0.5897, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1816 завершена --- tensor(0.5634, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1817 завершена --- tensor(0.4997, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1818 завершена --- tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1819 завершена --- tensor(0.5142, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1820 завершена --- tensor(0.4261, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1821 завершена --- tensor(0.7583, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1822 завершена --- tensor(0.4192, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1823 завершена --- tensor(0.4261, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1824 завершена --- tensor(0.5654, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1825 завершена --- tensor(0.4830, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1826 завершена --- tensor(0.5243, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1827 завершена --- tensor(0.4692, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1828 завершена --- tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1829 завершена --- tensor(0.4234, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1830 завершена --- tensor(0.4910, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1831 завершена --- tensor(0.4317, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1832 завершена --- tensor(0.5276, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1833 завершена --- tensor(0.4133, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1834 завершена --- tensor(0.4656, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1835 завершена --- tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1836 завершена --- tensor(0.4793, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1837 завершена --- tensor(0.4491, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1838 завершена --- tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1839 завершена --- tensor(0.4577, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1840 завершена --- tensor(0.4225, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1841 завершена --- tensor(0.4791, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1842 завершена --- tensor(0.4477, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1843 завершена --- tensor(0.4819, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1844 завершена --- tensor(0.4225, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1845 завершена --- tensor(0.3968, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1846 завершена --- tensor(0.8222, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1847 завершена --- tensor(0.4774, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1848 завершена --- tensor(1.0480, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1849 завершена --- tensor(0.4805, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1850 завершена --- tensor(0.5526, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1851 завершена --- tensor(0.5031, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1852 завершена --- tensor(0.4858, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1853 завершена --- tensor(0.4449, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1854 завершена --- tensor(0.4144, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1855 завершена --- tensor(0.4608, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1856 завершена --- tensor(0.4260, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1857 завершена --- tensor(0.5179, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1858 завершена --- tensor(0.5163, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1859 завершена --- tensor(0.4523, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1860 завершена --- tensor(0.4368, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1861 завершена --- tensor(0.4536, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1862 завершена --- tensor(0.8208, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1863 завершена --- tensor(0.4220, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1864 завершена --- tensor(0.7120, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1865 завершена --- tensor(0.5084, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1866 завершена --- tensor(0.4629, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1867 завершена --- tensor(0.4607, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1868 завершена --- tensor(0.4514, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1869 завершена --- tensor(0.4321, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1870 завершена --- tensor(0.4503, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1871 завершена --- tensor(0.8008, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1872 завершена --- tensor(0.4221, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1873 завершена --- tensor(0.4645, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1874 завершена --- tensor(0.4297, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1875 завершена --- tensor(0.4329, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1876 завершена --- tensor(0.4050, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1877 завершена --- tensor(0.4453, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1878 завершена --- tensor(0.5238, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1879 завершена --- tensor(0.5095, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1880 завершена --- tensor(0.4565, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1881 завершена --- tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1882 завершена --- tensor(0.4138, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1883 завершена --- tensor(0.4402, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1884 завершена --- tensor(0.3995, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1885 завершена --- tensor(1.1422, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1886 завершена --- tensor(0.4704, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1887 завершена --- tensor(0.7175, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1888 завершена --- tensor(0.4295, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1889 завершена --- tensor(0.4467, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1890 завершена --- tensor(0.4441, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1891 завершена --- tensor(0.4443, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1892 завершена --- tensor(0.4024, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1893 завершена --- tensor(0.4919, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1894 завершена --- tensor(0.4100, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1895 завершена --- tensor(0.4284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1896 завершена --- tensor(0.4102, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1897 завершена --- tensor(0.4116, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1898 завершена --- tensor(0.4128, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1899 завершена --- tensor(0.4173, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1900 завершена --- tensor(0.4129, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1901 завершена --- tensor(0.3806, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1902 завершена --- tensor(0.4323, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1903 завершена --- tensor(0.4080, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1904 завершена --- tensor(0.3894, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1905 завершена --- tensor(0.3854, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1906 завершена --- tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1907 завершена --- tensor(0.3651, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1908 завершена --- tensor(0.4141, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1909 завершена --- tensor(0.3953, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1910 завершена --- tensor(0.3728, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1911 завершена --- tensor(0.3826, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1912 завершена --- tensor(0.3779, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1913 завершена --- tensor(0.4083, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1914 завершена --- tensor(0.3892, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1915 завершена --- tensor(0.4132, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1916 завершена --- tensor(0.4124, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1917 завершена --- tensor(0.3591, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1918 завершена --- tensor(0.3887, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1919 завершена --- tensor(0.7757, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1920 завершена --- tensor(0.4678, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1921 завершена --- tensor(0.3678, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1922 завершена --- tensor(0.4149, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1923 завершена --- tensor(0.4266, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1924 завершена --- tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1925 завершена --- tensor(0.4505, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1926 завершена --- tensor(0.4006, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1927 завершена --- tensor(0.3942, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1928 завершена --- tensor(0.7777, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1929 завершена --- tensor(0.4583, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1930 завершена --- tensor(0.5097, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1931 завершена --- tensor(0.3921, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1932 завершена --- tensor(0.3940, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1933 завершена --- tensor(0.3853, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1934 завершена --- tensor(0.4268, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1935 завершена --- tensor(0.3931, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1936 завершена --- tensor(0.4104, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1937 завершена --- tensor(0.4061, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1938 завершена --- tensor(0.3929, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1939 завершена --- tensor(0.3856, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1940 завершена --- tensor(0.4030, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1941 завершена --- tensor(0.4192, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1942 завершена --- tensor(0.4147, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1943 завершена --- tensor(0.3892, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1944 завершена --- tensor(0.4037, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1945 завершена --- tensor(0.3837, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1946 завершена --- tensor(0.3916, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1947 завершена --- tensor(0.4513, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1948 завершена --- tensor(0.3924, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1949 завершена --- tensor(0.6228, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1950 завершена --- tensor(0.5272, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1951 завершена --- tensor(0.4468, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1952 завершена --- tensor(0.7820, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1953 завершена --- tensor(0.4000, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1954 завершена --- tensor(0.4631, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1955 завершена --- tensor(0.4500, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1956 завершена --- tensor(0.4284, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1957 завершена --- tensor(0.4052, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1958 завершена --- tensor(0.4084, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1959 завершена --- tensor(0.4375, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1960 завершена --- tensor(0.3984, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1961 завершена --- tensor(0.4202, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1962 завершена --- tensor(1.1270, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1963 завершена --- tensor(0.3742, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1964 завершена --- tensor(0.4442, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1965 завершена --- tensor(0.5991, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1966 завершена --- tensor(0.3865, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1967 завершена --- tensor(0.4700, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1968 завершена --- tensor(0.4382, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1969 завершена --- tensor(0.3973, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1970 завершена --- tensor(0.4152, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1971 завершена --- tensor(0.4442, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1972 завершена --- tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1973 завершена --- tensor(0.8317, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1974 завершена --- tensor(0.4381, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1975 завершена --- tensor(0.4326, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1976 завершена --- tensor(0.3811, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1977 завершена --- tensor(0.4314, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1978 завершена --- tensor(0.3775, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1979 завершена --- tensor(0.7581, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1980 завершена --- tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1981 завершена --- tensor(0.4060, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1982 завершена --- tensor(0.3912, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1983 завершена --- tensor(0.3938, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1984 завершена --- tensor(0.3977, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1985 завершена --- tensor(0.4783, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1986 завершена --- tensor(0.3974, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1987 завершена --- tensor(0.3701, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1988 завершена --- tensor(0.3800, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1989 завершена --- tensor(0.3675, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1990 завершена --- tensor(0.3624, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1991 завершена --- tensor(0.4576, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1992 завершена --- tensor(0.3723, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1993 завершена --- tensor(0.4532, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1994 завершена --- tensor(0.4376, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1995 завершена --- tensor(0.7050, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1996 завершена --- tensor(0.4217, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1997 завершена --- tensor(0.5313, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1998 завершена --- tensor(0.4371, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1999 завершена --- tensor(0.4303, grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 2000 завершена --- tensor(0.4240, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Функция для обучения модели\n",
    "def train(model, epochs, print_every=100):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for batch_idx, batch in enumerate(generate_chunk(), 1):\n",
    "            # Преобразование данных в тензоры\n",
    "            inputs = torch.tensor(batch[:, :-1], dtype=torch.long).to(device)  # (batch_size, seq_length)\n",
    "            targets = torch.tensor(batch[:, 1:], dtype=torch.long).to(device)  # (batch_size, seq_length)\n",
    "            \n",
    "            # Очистка градиентов\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            outputs, hidden = model(inputs, hidden.detach())\n",
    "            loss = criterion(outputs, targets.reshape(-1))\n",
    "            \n",
    "            # Обратный проход и оптимизация\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % print_every == 0:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Batch [{batch_idx}], Loss: {loss.item():.4f}')\n",
    "        if int(epoch % 100) == 0:\n",
    "            print(f'--- Epoch {epoch} завершена ---', loss)\n",
    "\n",
    "# Запуск обучения\n",
    "train(model, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст:\n",
      " мой дядя самых честных правилась;\n",
      "пойметерь от удна;\n",
      "она всех барно готовы,\n",
      "а что после должно думать\n",
      "и прочел и в санях;\n",
      "но мужить?». —\n",
      "«мой они в мыслев,\n",
      "и представит не сный почивой,\n",
      "то вопросила то ропщит готов бандвезь шарушкой и песнить мил он.\n",
      "нет, не седув закон?\n",
      "со воспоминать из татим,\n",
      "не достойна,\n",
      "с ольги упылкей;\n",
      "татьяна которанье,\n",
      "татьяну прелестью рощами, лука,\n",
      "под ним покелье, задумчивый, унылый\n",
      "пуст под стихает —\n",
      "из-блистательная дама\n",
      "я было ей так ли под хладноюбренье\n",
      "ее гремучию спит\n",
      "и что евгений\n",
      "кретили \n"
     ]
    }
   ],
   "source": [
    "# Функция для генерации текста\n",
    "def generate_text(model, start_str, length=100):\n",
    "    model.eval()\n",
    "    generated = start_str\n",
    "    hidden = model.init_hidden(1)  # batch_size=1\n",
    "    \n",
    "    # Преобразование начальной строки в индексы\n",
    "    input_seq = [token_to_idx.get(char, token_to_idx['<sos>']) for char in start_str]\n",
    "    input_tensor = torch.tensor([input_seq], dtype=torch.long).to(device)  # shape: (1, len(start_str))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Пропуск начальной строки через модель\n",
    "        for i in range(len(start_str)-1):\n",
    "            current_input = input_tensor[:, i].unsqueeze(1)  # shape: (1, 1)\n",
    "            output, hidden = model(current_input, hidden)\n",
    "        \n",
    "        # Получение последнего символа из начальной строки\n",
    "        last_char = input_tensor[:, -1].unsqueeze(1)  # shape: (1, 1)\n",
    "        \n",
    "        for _ in range(length):\n",
    "            # Вызов модели без лишнего измерения\n",
    "            output, hidden = model(last_char, hidden)  # last_char: (1, 1)\n",
    "            \n",
    "            # Преобразование выходов в вероятности\n",
    "            probs = F.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "            \n",
    "            # Выбор следующего символа на основе распределения вероятностей\n",
    "            next_char_idx = np.random.choice(len(probs), p=probs)\n",
    "            next_char = idx_to_token[next_char_idx]\n",
    "            generated += next_char\n",
    "            \n",
    "            # Подготовка следующего входа\n",
    "            last_char = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)  # shape: (1, 1)\n",
    "    \n",
    "    return generated\n",
    "\n",
    "\n",
    "# Пример генерации текста\n",
    "start_phrase = ' мой дядя самых честных правил'\n",
    "generated_text = generate_text(model, start_phrase, length=500)\n",
    "print(\"Сгенерированный текст:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
    "    '''\n",
    "    Функция генерирует текст, начиная с заданной начальной фразы.\n",
    "    \n",
    "    :param char_rnn: обученная модель RNN\n",
    "    :param seed_phrase: начальная фраза для генерации текста\n",
    "    :param max_length: максимальная длина генерируемого текста, включая начальную фразу\n",
    "    :param temperature: коэффициент для сэмплинга. \n",
    "                       Высокая температура приводит к более разнообразным результатам, \n",
    "                       низкая температура делает выбор более детерминированным.\n",
    "    :param device: устройство (CPU или GPU), на котором выполняется модель\n",
    "    :return: сгенерированный текст в виде строки\n",
    "    '''\n",
    "    \n",
    "    char_rnn.eval()  # Перевод модели в режим оценки\n",
    "    generated = seed_phrase if seed_phrase else ''\n",
    "    \n",
    "    # Преобразование начальной фразы в индексы\n",
    "    if seed_phrase is not None:\n",
    "        # Начинаем с токена <sos>\n",
    "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx.get(token, token_to_idx['<sos>']) for token in seed_phrase]\n",
    "    else: \n",
    "        x_sequence = [token_to_idx['<sos>']]\n",
    "    \n",
    "    # Преобразуем последовательность в тензор и переносим на устройство\n",
    "    input_tensor = torch.tensor([x_sequence], dtype=torch.long).to(device)  # shape: (1, len(x_sequence))\n",
    "    \n",
    "    # Инициализация скрытого состояния\n",
    "    hidden = char_rnn.init_hidden(1)  # batch_size=1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Пропуск начальной фразы через модель\n",
    "        for i in range(len(x_sequence)-1):\n",
    "            current_input = input_tensor[:, i].unsqueeze(1)  # shape: (1, 1)\n",
    "            output, hidden = char_rnn(current_input, hidden)\n",
    "        \n",
    "        # Получение последнего символа из начальной фразы\n",
    "        last_char = input_tensor[:, -1].unsqueeze(1)  # shape: (1, 1)\n",
    "        \n",
    "        for _ in range(max_length - len(x_sequence) + 1):\n",
    "            output, hidden = char_rnn(last_char, hidden)  # output: (1*1, num_tokens)\n",
    "            \n",
    "            # Применение температуры\n",
    "            logits = output / temperature\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy().squeeze()\n",
    "            \n",
    "            # Выбор следующего символа на основе распределения вероятностей\n",
    "            next_char_idx = np.random.choice(len(probs), p=probs)\n",
    "            next_char = idx_to_token[next_char_idx]\n",
    "            \n",
    "            # Добавление следующего символа к сгенерированному тексту\n",
    "            generated += next_char\n",
    "            \n",
    "            # Подготовка следующего ввода\n",
    "            last_char = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)\n",
    "    \n",
    "    return generated\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " мой дядя самых честных правилась, бредшии в нему не целу,\n",
      "и за столом у настая,\n",
      "пред помещик того, чтоб один и чах\n",
      "и молча онегина виданья?\n",
      "учтав и жаршен прокакое волненье,\n",
      "не отразился готовила\n",
      "про ольгу, за мире, степилась упрыв?\n",
      "\n",
      "\n",
      "\n",
      "xxv\n",
      "\n",
      "ужель зари в мой отдет\n",
      "и рифе тровую нас ним;\n",
      "онегин живо на гробом огадоет\n",
      "и посется он;\n",
      "что, и тафние лесов\n",
      "одна слова богата,\n",
      "всё поемено в окно уны!» —\n",
      "за них татьяне\n",
      "или мне часа по семьей мужезец важным любим,\n",
      "тут не были даже пережда,\n",
      "и мир блаженстви\n"
     ]
    }
   ],
   "source": [
    "print(generate_sample(model, ' мой дядя самых честных правил', max_length=500, temperature=0.8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generated_phrases = [\n",
    "    generate_sample(\n",
    "        model,\n",
    "        ' мой дядя самых честных правил',\n",
    "        max_length=500,\n",
    "        temperature=1.\n",
    "    ).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "import json\n",
    "if 'generated_phrases' not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        print(len(phrase))\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
    "    \n",
    "\n",
    "submission_dict = {\n",
    "    'token_to_idx': token_to_idx,\n",
    "    'generated_phrases': generated_phrases\n",
    "}\n",
    "\n",
    "with open('submission_dict.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "NLP HW Lab01_Poetry_generation.v5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
