{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FszmDROF12gL"
   },
   "source": [
    "## Домашнее задание №8.\n",
    "### Генерация поэзии с помощью нейронных сетей: шаг 1\n",
    "##### Авторы: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), Горохов Олег\n",
    "\n",
    "Ваша основная задача: научиться генерировать стихи с помощью простой рекуррентной нейронной сети (Vanilla RNN). В качестве корпуса текстов для обучения будет выступать роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VK6EUBMt12gN"
   },
   "outputs": [],
   "source": [
    "# Не меняйте блок кода ниже! Здесь указаны все необходимые import-ы\n",
    "# __________start of block__________\n",
    "import string\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEC9Irlo12gO",
    "outputId": "a5a97c97-2df9-4aa3-fac0-a2aedaa11462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device is available\n"
     ]
    }
   ],
   "source": [
    "# Не меняйте блок кода ниже!\n",
    "# __________start of block__________\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('{} device is available'.format(device))\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPenWOy01Ooa",
    "outputId": "a92e8e33-e009-4bd4-ac12-3b1b5e1cd3f2"
   },
   "source": [
    "#### 1. Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhD8UJzN12gP",
    "outputId": "5784c0dc-e1a4-4458-eddc-6652e91f9ea5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://raw.githubusercontent.com/MSUcourses/Data-Analysis-with-Python/main/Deep%20Learning/onegin_hw07.txt\n",
      "To: c:\\Users\\vdoff\\Desktop\\DL\\onegin.txt\n",
      "\n",
      "  0%|          | 0.00/82.7k [00:00<?, ?B/s]\n",
      "263kB [00:00, 5.80MB/s]                    \n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "!gdown https://raw.githubusercontent.com/MSUcourses/Data-Analysis-with-Python/main/Deep%20Learning/onegin_hw07.txt -O ./onegin.txt\n",
    "\n",
    "with open('onegin.txt', 'r', encoding='utf8') as iofile:\n",
    "    text = iofile.readlines()\n",
    "\n",
    "text = \"\".join([x.replace('\\t\\t', '').lower() for x in text]) # Убираем лишние символы табуляций, приводим все буквы к нижнему регистру\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR6n1UmvZ8DC"
   },
   "source": [
    "Выведем несколько первых символов входного текста. Видим, что символы табуляций удалены, буквы приведены к нижнему регистру. Символы \\n мы оставляем - чтобы научить сеть генерировать символ \\n, когда нужно перейти на новую строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ksrWh_hvZsY_",
    "outputId": "5253bfc4-35be-4a91-cd98-13dbf86a8e61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni\\n\\n«мой дядя самых честных правил,\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQYpmGfR_gJ8"
   },
   "source": [
    "#### 2. Построение словаря и предобработка текста\n",
    "В данном задании требуется построить языковую модель на уровне символов. Приведем весь текст к нижнему регистру и построим словарь из всех символов в доступном корпусе текстов. Также добавим технический токен `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyYTS2kC12gQ",
    "outputId": "87ec6b3b-b4e3-4ff4-f419-69d5226da6c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "# Не меняйте блок кода ниже!\n",
    "# __________start of block__________\n",
    "tokens = sorted(set(text.lower())) + ['<sos>'] # Строим множество всех токенов-символов и добавляем к нему служебный токен <sos>\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "assert num_tokens == 84, \"Check the tokenization process\"\n",
    "\n",
    "token_to_idx = {x: idx for idx, x in enumerate(tokens)} # Строим словарь с ключами-токенами и значениями-индексами в списке токенов\n",
    "idx_to_token = {idx: x for idx, x in enumerate(tokens)} # Строим обратный словарь (чтобы по индексу можно было получить токен)\n",
    "\n",
    "assert len(tokens) == len(token_to_idx), \"Mapping should be unique\"\n",
    "\n",
    "print(\"Seems fine!\")\n",
    "\n",
    "\n",
    "text_encoded = [token_to_idx[x] for x in text]\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITona8rr12gQ"
   },
   "source": [
    "__Ваша задача__: обучить классическую рекуррентную нейронную сеть (Vanilla RNN) предсказывать следующий символ на полученном корпусе текстов и сгенерировать последовательность длины 100 для фиксированной начальной фразы.\n",
    "\n",
    "Вы можете воспользоваться кодом с занятия №6 или же обратиться к следующим ссылкам:\n",
    "* Замечательная статья за авторством Andrej Karpathy об использовании RNN: [link](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "* Пример char-rnn от Andrej Karpathy: [github repo](https://github.com/karpathy/char-rnn)\n",
    "* Замечательный пример генерации поэзии Шекспира: [github repo](https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb)\n",
    "\n",
    "Данное задание является достаточно творческим. Не страшно, если поначалу оно вызывает затруднения. Последняя ссылка в списке выше может быть особенно полезна в данном случае.\n",
    "\n",
    "Далее для вашего удобства реализована функция, которая генерирует случайный батч размера `batch_size` из строк длиной `seq_length`. Вы можете использовать его при обучении модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B1R2KoN212gQ"
   },
   "outputs": [],
   "source": [
    "# Не меняйте код ниже\n",
    "# __________start of block__________\n",
    "batch_size = 256 # Размер батча. Батч - это набор последовательностей символов.\n",
    "seq_length = 100 # Максимальная длина одной последовательности символов в батче\n",
    "start_column = np.zeros((batch_size, 1), dtype=int) + token_to_idx['<sos>'] # Добавляем в начало каждой строки технический символ - для определения начального состояния сети\n",
    "\n",
    "def generate_chunk():\n",
    "    global text_encoded, start_column, batch_size, seq_length\n",
    "\n",
    "    start_index = np.random.randint(0, len(text_encoded) - batch_size*seq_length - 1) # Случайным образом выбираем индекс начального символа в батче\n",
    "    # Строим непрерывный батч.\n",
    "    # Для этого выбираем в исходном тексте подпоследовательность, которая начинается с индекса start_index и имеет размер batch_size*seq_length.\n",
    "    # Затем мы делим эту подпоследовательность на batch_size последовательностей размера seq_length. Это и будет батч, матрица размера batch_size*seq_length.\n",
    "    # В каждой строке матрицы будут указаны индексы\n",
    "    data = np.array(text_encoded[start_index:start_index + batch_size*seq_length]).reshape((batch_size, -1))\n",
    "    yield np.hstack((start_column, data))\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHohQt0V12gR"
   },
   "source": [
    "Пример батча:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyuWYgeZ12gR",
    "outputId": "1fecf762-731c-4713-dce1-02c73841f341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83,  1, 62, ..., 47, 50, 63],\n",
       "       [83, 45,  5, ..., 72, 62, 56],\n",
       "       [83, 50, 54, ..., 61, 59, 55],\n",
       "       ...,\n",
       "       [83, 63,  1, ..., 63, 50, 54],\n",
       "       [83,  0, 60, ..., 59, 61, 76],\n",
       "       [83, 49, 59, ..., 59,  1, 47]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generate_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ5vfEKM12gS"
   },
   "source": [
    "Далее вам предстоит написать код для обучения модели и генерации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7XBmwWxp12gS"
   },
   "outputs": [],
   "source": [
    "# Определение модели Vanilla RNN\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, output_size, num_layers=1):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Встраивание символов\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        \n",
    "        # Рекуррентный слой\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, nonlinearity='tanh', batch_first=True)\n",
    "        \n",
    "        # Полносвязный слой\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embed_size)\n",
    "        out, hidden = self.rnn(embedded, hidden)  # out: (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.size(0)*out.size(1), self.hidden_size)  # (batch_size*seq_length, hidden_size)\n",
    "        out = self.fc(out)  # (batch_size*seq_length, output_size)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Инициализация скрытого состояния\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.003\n",
    "\n",
    "# Инициализация модели\n",
    "model = VanillaRNN(input_size=num_tokens, \n",
    "                   embed_size=embed_size, \n",
    "                   hidden_size=hidden_size, \n",
    "                   output_size=num_tokens, \n",
    "                   num_layers=num_layers).to(device)\n",
    "\n",
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 100 завершена --- tensor(1.9752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 200 завершена --- tensor(1.7173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 300 завершена --- tensor(1.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 400 завершена --- tensor(1.2292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 500 завершена --- tensor(1.0993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 600 завершена --- tensor(0.9604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 700 завершена --- tensor(0.7223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 800 завершена --- tensor(0.6606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 900 завершена --- tensor(0.5725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1000 завершена --- tensor(0.6021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1100 завершена --- tensor(0.4920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1200 завершена --- tensor(0.4654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1300 завершена --- tensor(0.4979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1400 завершена --- tensor(0.4990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1500 завершена --- tensor(0.3869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1600 завершена --- tensor(0.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1700 завершена --- tensor(0.4031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1800 завершена --- tensor(0.4587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 1900 завершена --- tensor(0.3813, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "--- Epoch 2000 завершена --- tensor(0.4585, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Функция для обучения модели\n",
    "def train(model, epochs, print_every=100):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for batch_idx, batch in enumerate(generate_chunk(), 1):\n",
    "            # Преобразование данных в тензоры\n",
    "            inputs = torch.tensor(batch[:, :-1], dtype=torch.long).to(device)  # (batch_size, seq_length)\n",
    "            targets = torch.tensor(batch[:, 1:], dtype=torch.long).to(device)  # (batch_size, seq_length)\n",
    "            \n",
    "            # Очистка градиентов\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Прямой проход\n",
    "            outputs, hidden = model(inputs, hidden.detach())\n",
    "            loss = criterion(outputs, targets.reshape(-1))\n",
    "            \n",
    "            # Обратный проход и оптимизация\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % print_every == 0:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Batch [{batch_idx}], Loss: {loss.item():.4f}')\n",
    "        if int(epoch % 100) == 0:\n",
    "            print(f'--- Epoch {epoch} завершена ---', loss)\n",
    "\n",
    "# Запуск обучения\n",
    "train(model, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOq8SszD12gS"
   },
   "source": [
    "В качестве иллюстрации ниже доступен график значений функции потерь, построенный в ходе обучения авторской сети (сам код для ее обучения вам и предстоит написать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1DVfcmS12gS",
    "outputId": "4cac4ac1-85ce-4088-e67b-5d422008408c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPLGR7Wz12gS"
   },
   "source": [
    "Шаблон функции `generate_sample` также доступен ниже. Вы можете как дозаполнить его, так и написать свою собственную функцию с нуля. Не забывайте, что все примеры в обучающей выборке начинались с токена `<sos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e7ZX-JGi12gS"
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=None, max_length=200, temperature=1.0, device=device):\n",
    "    '''\n",
    "    Функция генерирует текст, начиная с заданной начальной фразы.\n",
    "    \n",
    "    :param char_rnn: обученная модель RNN\n",
    "    :param seed_phrase: начальная фраза для генерации текста\n",
    "    :param max_length: максимальная длина генерируемого текста, включая начальную фразу\n",
    "    :param temperature: коэффициент для сэмплинга. \n",
    "                       Высокая температура приводит к более разнообразным результатам, \n",
    "                       низкая температура делает выбор более детерминированным.\n",
    "    :param device: устройство (CPU или GPU), на котором выполняется модель\n",
    "    :return: сгенерированный текст в виде строки\n",
    "    '''\n",
    "    \n",
    "    char_rnn.eval()  # Перевод модели в режим оценки\n",
    "    generated = seed_phrase if seed_phrase else ''\n",
    "    \n",
    "    # Преобразование начальной фразы в индексы\n",
    "    if seed_phrase is not None:\n",
    "        # Начинаем с токена <sos>\n",
    "        x_sequence = [token_to_idx['<sos>']] + [token_to_idx.get(token, token_to_idx['<sos>']) for token in seed_phrase]\n",
    "    else: \n",
    "        x_sequence = [token_to_idx['<sos>']]\n",
    "    \n",
    "    # Преобразуем последовательность в тензор и переносим на устройство\n",
    "    input_tensor = torch.tensor([x_sequence], dtype=torch.long).to(device)  # shape: (1, len(x_sequence))\n",
    "    \n",
    "    # Инициализация скрытого состояния\n",
    "    hidden = char_rnn.init_hidden(1)  # batch_size=1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Пропуск начальной фразы через модель\n",
    "        for i in range(len(x_sequence)-1):\n",
    "            current_input = input_tensor[:, i].unsqueeze(1)  # shape: (1, 1)\n",
    "            output, hidden = char_rnn(current_input, hidden)\n",
    "        \n",
    "        # Получение последнего символа из начальной фразы\n",
    "        last_char = input_tensor[:, -1].unsqueeze(1)  # shape: (1, 1)\n",
    "        \n",
    "        for _ in range(max_length - len(x_sequence) + 1):\n",
    "            output, hidden = char_rnn(last_char, hidden)  # output: (1*1, num_tokens)\n",
    "            \n",
    "            # Применение температуры\n",
    "            logits = output / temperature\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy().squeeze()\n",
    "            \n",
    "            # Выбор следующего символа на основе распределения вероятностей\n",
    "            next_char_idx = np.random.choice(len(probs), p=probs)\n",
    "            next_char = idx_to_token[next_char_idx]\n",
    "            \n",
    "            # Добавление следующего символа к сгенерированному тексту\n",
    "            generated += next_char\n",
    "            \n",
    "            # Подготовка следующего ввода\n",
    "            last_char = torch.tensor([[next_char_idx]], dtype=torch.long).to(device)\n",
    "    \n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if0Zdsq_12gS"
   },
   "source": [
    "Пример текста сгенерированного обученной моделью доступен ниже. Не страшно, что в тексте много несуществующих слов. Используемая модель очень проста: это простая классическая RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yF-Iuqmw12gS",
    "outputId": "6f95b0e9-b5e9-42b7-9222-6a4d0d21e896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " мой дядя самых честных правил\n",
      "он твоя важно роковый детьмирать?» —\n",
      "«не мольно голоиной,\n",
      "выходят котроду, четвертый.\n",
      "я их имею поэт\n",
      "во-прежнему сердечно обман\n",
      "диш она, как люблю такого оборые. суждений\n",
      "хать предо мной;\n",
      "благословен и это грустит он и госты!\n",
      "\n",
      "\n",
      "\n",
      "xxvii\n",
      "\n",
      "«не слушать забываться желает\n",
      "такой бесчувственно-покорна,\n",
      "не может ольгою преданной\n",
      "привлече суровым повелела!\n",
      "«я важны взоры,\n",
      "и с оходит в отких и томный вис одушевнов\n",
      "издни роман,\n",
      "с такою душой.\n",
      "ромний целью в зеркало ленский; хох\n"
     ]
    }
   ],
   "source": [
    "print(generate_sample(model, ' мой дядя самых честных правил', max_length=500, temperature=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwFvHiKP12gS"
   },
   "source": [
    "### Сдача задания\n",
    "Сгенерируйте десять последовательностей длиной 500, используя строку ' мой дядя самых честных правил'. Температуру для генерации выберите самостоятельно на основании визуального качества генериуремого текста. Не забудьте удалить все технические токены в случае их наличия.\n",
    "\n",
    "Сгенерированную последовательность сохрание в переменную `generated_phrase` и сдайте сгенерированный ниже файл в контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sB5p9j9T12gT"
   },
   "outputs": [],
   "source": [
    "seed_phrase = ' мой дядя самых честных правил'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Qe9T5-Op12gT"
   },
   "outputs": [],
   "source": [
    "\n",
    "generated_phrases = [\n",
    "    generate_sample(\n",
    "        model,\n",
    "        ' мой дядя самых честных правил',\n",
    "        max_length=500,\n",
    "        temperature=1.\n",
    "    ).replace('<sos>', '')\n",
    "    for _ in range(10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kKTbJtIi12gT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw07.npy`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "if 'generated_phrases' not in locals():\n",
    "    raise ValueError(\"Please, save generated phrases to `generated_phrases` variable\")\n",
    "\n",
    "for phrase in generated_phrases:\n",
    "\n",
    "    if not isinstance(phrase, str):\n",
    "        raise ValueError(\"The generated phrase should be a string\")\n",
    "\n",
    "    if len(phrase) != 500:\n",
    "        raise ValueError(\"The `generated_phrase` length should be equal to 500\")\n",
    "\n",
    "    assert all([x in set(tokens) for x in set(list(phrase))]), 'Unknown tokens detected, check your submission!'\n",
    "\n",
    "\n",
    "submission_dict = {\n",
    "    'token_to_idx': token_to_idx,\n",
    "    'generated_phrases': generated_phrases\n",
    "}\n",
    "\n",
    "np.save('submission_dict_hw07.npy', submission_dict, allow_pickle=True)\n",
    "print('File saved to `submission_dict_hw07.npy`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7ONIO0612gT"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
